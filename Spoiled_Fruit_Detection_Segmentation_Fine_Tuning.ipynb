{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Y25OucKc0b8-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLv5Jp81elq3"
   },
   "source": [
    "# Courtesy and Insights\n",
    "\n",
    "https://blog.roboflow.com/instance-segmentation-roboflow/\n",
    "\n",
    "https://blog.roboflow.com/how-to-train-yolov8-instance-segmentation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FAfaMfMF0hzx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1wKLjDvevFo"
   },
   "source": [
    "# Step 1. Generate video of fresh and spoiled lemon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cobgqnyxe0dG"
   },
   "source": [
    "# Step 2. Convert video frames to jpeg images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KB8yAgpke4AZ"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Path to the video file\n",
    "video_path = '/content/drive/My Drive/Colab Notebooks/{input}.mp4'\n",
    "\n",
    "# Directory to save the frames locally in Colab\n",
    "save_dir = 'xxx'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Capture the video from the file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "current_frame = 0\n",
    "while True:\n",
    "    # Read the next frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Finished reading the video.\")\n",
    "        break\n",
    "\n",
    "    # Save the frame as a JPEG file\n",
    "    save_path = os.path.join(save_dir, f\"frame_{current_frame:04d}.jpg\")\n",
    "    cv2.imwrite(save_path, frame)\n",
    "    print(f\"Saved: {save_path}\")\n",
    "\n",
    "    current_frame += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "print(\"All frames are extracted and saved locally.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yt_bkEjle8nh"
   },
   "source": [
    "# Step 3. Upload images to Roboflow.\n",
    "\n",
    "Do manual annotation\n",
    "\n",
    "Add Labels\n",
    "\n",
    "Add Bounding boxes.\n",
    "\n",
    "Draw polygon using Smart Polygon tool and Free form polygon tool\n",
    "\n",
    "Split Images to train, test, valid datasets\n",
    "\n",
    "https://universe.roboflow.com/test-4h9f7/fruit-spoil-detection#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOEsC1CafL3O"
   },
   "source": [
    "# Step 4. Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AmAoGm410h4W",
    "outputId": "0972be84-a0fc-489e-ba69-239cba66b58f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHbCZhone0BJ"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nT4pBz_u0pLe",
    "outputId": "5029b520-4652-4d2c-a52e-d6c59ee55f4a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.196 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 33.6/78.2 GB disk)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics==8.0.196 -q\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "XlLqwkTL0wxM"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nH513FwS0yrp",
    "outputId": "9ecf1165-9cee-409a-8e3e-e1bbb3a675d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt-get install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zLW8DM2E0yzZ",
    "outputId": "e8c3d408-89b6-42fc-a18c-650577e641b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "YOUR_API_KEY = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xhaop2H700wO",
    "outputId": "c9787352-cc12-475c-82e3-087d75320a7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/datasets\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "\n",
    "!mkdir {HOME}/datasets\n",
    "%cd {HOME}/datasets\n",
    "\n",
    "!pip install roboflow --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9sK8E4PP03BZ",
    "outputId": "332354be-2254-4dd1-edc0-e9c4c0882c2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'welcome': 'Welcome to the Roboflow API.', 'instructions': 'You are successfully authenticated.', 'docs': 'https://docs.roboflow.com', 'workspace': 'test-4h9f7'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "#YOUR_API_KEY = \"YOUR_ACTUAL_API_KEY\"  # Replace with your actual API key\n",
    "\n",
    "url = \"https://api.roboflow.com/\"\n",
    "headers = {\"Authorization\": f\"Bearer {YOUR_API_KEY}\"}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    workspaces = response.json()\n",
    "    print(workspaces)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCMCAFuQfQ31"
   },
   "source": [
    "# Step 5. Download Dataset from roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BsjdwCT40-wC",
    "outputId": "ff100c93-e91e-4abe-f262-5867bb237739"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in fruit-spoil-detection-1 to yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25271/25271 [00:02<00:00, 8780.11it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to fruit-spoil-detection-1 in yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 630/630 [00:00<00:00, 1590.63it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=YOUR_API_KEY)\n",
    "\n",
    "\n",
    "\n",
    "project = rf.workspace(\"test-4h9f7\").project(\"fruit-spoil-detection\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jzDwUGtl2eVs",
    "outputId": "6ec505eb-386e-460b-800d-fc73baa12dff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4\n",
      "drwxr-xr-x 5 root root 4096 Aug 14 05:31 fruit-spoil-detection-1\n"
     ]
    }
   ],
   "source": [
    "!ls -ltr /content/datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Czt_a5mfVpe"
   },
   "source": [
    "# Step 6. Train ultralytics YOLO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UpTd4K6r1CLc",
    "outputId": "cc246574-1e99-4aaf-8eac-c1effe70b618"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt to 'yolov8m-seg.pt'...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 52.4M/52.4M [00:01<00:00, 28.6MB/s]\n",
      "New https://pypi.org/project/ultralytics/8.2.77 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.196 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolov8m-seg.pt, data=/content/datasets/fruit-spoil-detection-1/data.yaml, epochs=50, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 42.8MB/s]\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.23M/6.23M [00:00<00:00, 203MB/s]\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/fruit-spoil-detection-1/train/labels... 270 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 270/270 [00:00<00:00, 1242.34it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/fruit-spoil-detection-1/train/labels.cache\n",
      "Got processor for bboxes, but no transform to process it.\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/fruit-spoil-detection-1/valid/labels... 26 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [00:00<00:00, 1042.27it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/fruit-spoil-detection-1/valid/labels.cache\n",
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/50      8.07G     0.6217      1.438       1.87       1.05         87        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:23<00:00,  1.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.05it/s]\n",
      "                   all         26        120      0.884      0.809      0.862      0.759      0.884      0.809       0.86      0.743\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/50      8.02G     0.5026     0.9353     0.6998      0.939        107        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:15<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         26        120      0.673      0.785      0.752      0.596      0.674      0.785      0.737      0.498\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/50      8.06G     0.5316     0.9123     0.6362     0.9286        120        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         26        120      0.868      0.507      0.756      0.656      0.868      0.507      0.756      0.565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/50         8G     0.5761     0.8593     0.5765     0.9457        109        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:13<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.64it/s]\n",
      "                   all         26        120    0.00704      0.194    0.00304     0.0015    0.00344      0.177    0.00217    0.00104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/50         8G     0.5758     0.9324     0.5853     0.9656         90        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:13<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         26        120       0.82       0.82      0.871      0.699      0.814      0.813       0.86      0.626\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/50      8.05G     0.5708      0.838     0.5568     0.9499        111        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.02it/s]\n",
      "                   all         26        120       0.85      0.898      0.913      0.735      0.847       0.89      0.909      0.726\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/50      8.05G     0.5758     0.8963     0.5419     0.9495        105        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:11<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.35it/s]\n",
      "                   all         26        120      0.936      0.899       0.94      0.765      0.936      0.899      0.939      0.741\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/50      7.96G      0.596      0.928     0.5993     0.9638        112        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.10it/s]\n",
      "                   all         26        120      0.586      0.368      0.358      0.275        0.6      0.385      0.362      0.246\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/50      8.38G     0.5455     0.7973     0.5414     0.9448        109        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:11<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.01it/s]\n",
      "                   all         26        120      0.836      0.835      0.876      0.749       0.82      0.847      0.871      0.725\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/50      8.03G     0.5495     0.7987      0.506     0.9389        119        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.80it/s]\n",
      "                   all         26        120      0.866      0.878      0.925      0.783      0.847      0.857      0.907      0.774\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/50      8.02G     0.5288     0.7552     0.4888     0.9397         78        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                   all         26        120      0.861      0.849      0.935      0.823      0.847      0.837      0.929      0.808\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/50      8.01G     0.5237     0.7582     0.4646     0.9302        107        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:13<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.84it/s]\n",
      "                   all         26        120       0.62      0.928      0.683      0.629      0.617      0.921      0.683      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/50      8.28G     0.4899      0.721     0.4687     0.9321         88        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:13<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         26        120      0.876      0.868      0.934      0.826      0.876      0.868      0.929      0.814\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/50      8.01G     0.4771     0.7149       0.43      0.914         79        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:13<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.80it/s]\n",
      "                   all         26        120      0.871       0.93      0.948      0.857      0.858      0.918      0.944      0.849\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/50      8.01G      0.459     0.7317     0.4243     0.9043        124        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all         26        120      0.916      0.911      0.939      0.828      0.916      0.911      0.938      0.739\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/50      8.03G      0.506     0.7795     0.4599     0.9384        108        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:11<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.11it/s]\n",
      "                   all         26        120       0.94      0.941      0.946       0.86      0.908       0.91      0.903      0.655\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/50      8.35G     0.4792       0.73     0.4329     0.9225         84        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                   all         26        120      0.898      0.951       0.97        0.9      0.913      0.912      0.965      0.885\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/50         8G     0.4363     0.6816     0.3925     0.8928        116        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:11<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.05it/s]\n",
      "                   all         26        120       0.94      0.931      0.963      0.878       0.94      0.931      0.961      0.858\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/50         8G     0.4765      0.788     0.4216     0.9212         92        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         26        120      0.932      0.958      0.973      0.878      0.918      0.944      0.966      0.865\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/50      8.02G     0.4793     0.7197      0.434     0.9159         93        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.90it/s]\n",
      "                   all         26        120      0.905      0.958      0.958      0.876      0.913      0.951      0.954      0.875\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/50      8.41G     0.4566     0.6554     0.4007     0.8983         89        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:13<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.86it/s]\n",
      "                   all         26        120      0.921      0.965      0.969      0.898      0.907      0.951      0.966      0.883\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/50      7.99G     0.4465     0.6705     0.4188     0.8999         88        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:13<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]\n",
      "                   all         26        120      0.936      0.941      0.978      0.906      0.949      0.924      0.972      0.885\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/50      8.08G     0.4232     0.6348     0.4022      0.901         91        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.23s/it]\n",
      "                   all         26        120      0.944      0.948      0.968      0.889      0.944      0.948      0.966      0.865\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/50      8.06G      0.407     0.6347     0.3997     0.8794        111        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:11<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                   all         26        120      0.938      0.952      0.974      0.909      0.931      0.946      0.972      0.893\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/50      7.97G     0.4001     0.5996     0.3761     0.8864        143        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.21s/it]\n",
      "                   all         26        120      0.944      0.958      0.977      0.901      0.944      0.958      0.977      0.894\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/50      7.98G     0.4171     0.6329     0.3852     0.9002        106        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:11<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.02it/s]\n",
      "                   all         26        120       0.91      0.971      0.972      0.898      0.903      0.964      0.969      0.884\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      27/50      8.08G     0.4006     0.6177     0.3671     0.8895         91        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:11<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.23it/s]\n",
      "                   all         26        120      0.942      0.924      0.968      0.903      0.935      0.917      0.965      0.876\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/50      8.14G     0.4127     0.6207     0.3692     0.8998         87        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.90it/s]\n",
      "                   all         26        120      0.892      0.941      0.959      0.888      0.852      0.945      0.953      0.869\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/50      7.96G     0.4217     0.6455     0.3619      0.904         92        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:13<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.89it/s]\n",
      "                   all         26        120      0.917      0.931      0.964      0.904      0.917      0.931      0.963       0.89\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      30/50      8.08G     0.4082     0.6166     0.3777      0.888         81        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:13<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.86it/s]\n",
      "                   all         26        120      0.932      0.957      0.966      0.896      0.906      0.947      0.961      0.886\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      31/50      7.97G     0.4174     0.6179     0.3568      0.894        101        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.23s/it]\n",
      "                   all         26        120      0.917      0.962      0.969      0.902      0.893      0.972      0.967      0.894\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      32/50      7.96G     0.4094     0.6088     0.3649     0.8967         97        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.08it/s]\n",
      "                   all         26        120      0.927      0.944      0.972      0.899      0.882      0.953      0.967      0.886\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      33/50      8.09G     0.3838     0.5797     0.3398     0.8856         81        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:11<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.35it/s]\n",
      "                   all         26        120      0.901      0.965      0.971      0.903      0.888      0.951      0.966      0.892\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      34/50      7.97G     0.3578     0.5575     0.3395     0.8736        106        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.88it/s]\n",
      "                   all         26        120      0.941      0.979       0.98      0.931      0.941      0.979       0.98      0.917\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      35/50      8.03G     0.3895      0.583     0.3586     0.8805         83        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:13<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.89it/s]\n",
      "                   all         26        120      0.915      0.965      0.975      0.913      0.942      0.924      0.974      0.902\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      36/50      8.08G     0.3602     0.5683     0.3357     0.8772         84        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:13<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.90it/s]\n",
      "                   all         26        120      0.933      0.946      0.975      0.912      0.938      0.931      0.973      0.896\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      37/50      8.31G     0.3765      0.593      0.356     0.8901        106        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:13<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.89it/s]\n",
      "                   all         26        120       0.95      0.972      0.976      0.923      0.943      0.965      0.973      0.904\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      38/50      7.98G     0.3492     0.5389     0.3393     0.8813        112        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:13<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.87it/s]\n",
      "                   all         26        120      0.929      0.938      0.967      0.899      0.892      0.956      0.957      0.878\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      39/50      7.97G     0.3611     0.5611     0.3475     0.8837         90        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.88it/s]\n",
      "                   all         26        120      0.915      0.972      0.969      0.908      0.898      0.972      0.966      0.892\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      40/50      8.03G     0.3463     0.5517     0.3242     0.8728        105        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:13<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.91it/s]\n",
      "                   all         26        120      0.909      0.961      0.962      0.909      0.938      0.919      0.961      0.893\n",
      "Closing dataloader mosaic\n",
      "Got processor for bboxes, but no transform to process it.\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      41/50      8.23G     0.3091     0.5091     0.3103     0.8648         56        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:16<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.89it/s]\n",
      "                   all         26        120      0.917      0.931      0.962      0.895      0.902      0.917      0.958      0.887\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      42/50      7.91G     0.3166     0.5349     0.2929     0.8628         58        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.90it/s]\n",
      "                   all         26        120      0.891      0.961       0.97      0.903      0.887      0.931      0.964       0.89\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      43/50      7.89G     0.3038     0.4853     0.2855     0.8572         60        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.86it/s]\n",
      "                   all         26        120      0.919      0.949      0.974      0.923      0.962      0.908      0.972      0.909\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      44/50      7.93G     0.2922     0.4697     0.2825     0.8579         56        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:11<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                   all         26        120      0.936      0.936      0.976      0.921      0.957      0.931      0.975      0.912\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      45/50      8.22G     0.2928     0.4847     0.2768     0.8506         53        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:11<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                   all         26        120      0.916      0.958      0.974      0.915        0.9      0.951      0.973      0.906\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      46/50      7.92G     0.2882     0.4959      0.273     0.8526         57        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:11<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                   all         26        120      0.949      0.937       0.97      0.916      0.949      0.937       0.97      0.904\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      47/50      7.92G      0.291      0.479     0.2605      0.844         55        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:11<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.86it/s]\n",
      "                   all         26        120      0.937      0.958       0.97      0.922       0.94      0.943       0.97       0.91\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      48/50      7.94G     0.2816     0.4851     0.2575      0.855         58        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.90it/s]\n",
      "                   all         26        120      0.929      0.938      0.973       0.91      0.921      0.924      0.968      0.899\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      49/50       7.9G     0.2821     0.4606      0.264     0.8601         54        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         26        120      0.931      0.938      0.975      0.908      0.916      0.924       0.97      0.898\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      50/50      7.91G     0.2753      0.466     0.2466      0.851         62        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.88it/s]\n",
      "                   all         26        120       0.93      0.943      0.977      0.915      0.915      0.929      0.973      0.905\n",
      "\n",
      "50 epochs completed in 0.231 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.196 üöÄ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         26        120      0.941      0.979       0.98      0.931      0.941      0.979       0.98      0.918\n",
      "                 fresh         26         48      0.936          1      0.992      0.977      0.936          1      0.992      0.971\n",
      "               spoiled         26         72      0.945      0.957      0.967      0.885      0.945      0.957      0.967      0.865\n",
      "Speed: 0.2ms preprocess, 14.8ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8m-seg.pt')\n",
    "\n",
    "results = model.train(data=f\"{dataset.location}/data.yaml\", epochs=50, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Wi1vYFpy1hfg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "V612EAb42Ohc"
   },
   "outputs": [],
   "source": [
    "#!ls -ltr /content/datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAakFdy3fa1R"
   },
   "source": [
    "# Step 7. Run Prediction on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sNWzcvql2BdQ",
    "outputId": "5a52980a-b322-4140-d859-8d9e92d2d51b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/13 /content/datasets/fruit-spoil-detection-1/test/images/frame_0001_jpg.rf.633cc298dfd9fe8c050e106f18c84578.jpg: 640x640 2 freshs, 3 spoileds, 49.3ms\n",
      "image 2/13 /content/datasets/fruit-spoil-detection-1/test/images/frame_0003_jpg.rf.32f2035a05a361a52160107e11708e55.jpg: 640x640 2 freshs, 2 spoileds, 39.1ms\n",
      "image 3/13 /content/datasets/fruit-spoil-detection-1/test/images/frame_0006_jpg.rf.5fc834bf7cbd52c8a739a5ed69b34e37.jpg: 640x640 2 freshs, 2 spoileds, 38.7ms\n",
      "image 4/13 /content/datasets/fruit-spoil-detection-1/test/images/frame_0010_jpg.rf.b8a04b4f7c4f6c731cc72b9644de6d3a.jpg: 640x640 2 freshs, 2 spoileds, 36.0ms\n",
      "image 5/13 /content/datasets/fruit-spoil-detection-1/test/images/frame_0011_jpg.rf.92590df2f8ad2472d3e950efe37c2014.jpg: 640x640 2 freshs, 2 spoileds, 36.2ms\n",
      "image 6/13 /content/datasets/fruit-spoil-detection-1/test/images/frame_0043_jpg.rf.9fce5495d416466ab7531d630e167ecd.jpg: 640x640 2 freshs, 3 spoileds, 35.6ms\n",
      "image 7/13 /content/datasets/fruit-spoil-detection-1/test/images/frame_0047_jpg.rf.5bd4e80a96798e11f317da19900f0673.jpg: 640x640 1 fresh, 6 spoileds, 28.3ms\n",
      "image 8/13 /content/datasets/fruit-spoil-detection-1/test/images/frame_0052_jpg.rf.a309d352f2feac43ab5e2602aa4fa0ae.jpg: 640x640 1 fresh, 4 spoileds, 26.2ms\n",
      "image 9/13 /content/datasets/fruit-spoil-detection-1/test/images/frame_0078_jpg.rf.2b82af13d1b56e46ae541b75290aaca2.jpg: 640x640 1 fresh, 4 spoileds, 26.6ms\n",
      "image 10/13 /content/datasets/fruit-spoil-detection-1/test/images/frame_0086_jpg.rf.a5986d6b56f3441a2047b5e5797feb04.jpg: 640x640 1 fresh, 6 spoileds, 26.2ms\n",
      "image 11/13 /content/datasets/fruit-spoil-detection-1/test/images/frame_0099_jpg.rf.358744d766386ce0e596ebf5b0f0e933.jpg: 640x640 2 freshs, 3 spoileds, 24.1ms\n",
      "image 12/13 /content/datasets/fruit-spoil-detection-1/test/images/frame_0119_jpg.rf.58f0fc67757b4bd5640e1b31fc4a888c.jpg: 640x640 3 freshs, 3 spoileds, 23.9ms\n",
      "image 13/13 /content/datasets/fruit-spoil-detection-1/test/images/frame_0125_jpg.rf.224506015b0821fbc7e1936be67d1d6f.jpg: 640x640 4 freshs, 2 spoileds, 24.2ms\n",
      "Speed: 4.0ms preprocess, 31.9ms inference, 7.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'fresh', 1: 'spoiled'}\n",
      "orig_img: array([[[147, 145, 151],\n",
      "        [166, 164, 170],\n",
      "        [150, 148, 154],\n",
      "        ...,\n",
      "        [ 89,  92, 100],\n",
      "        [120, 123, 131],\n",
      "        [112, 115, 123]],\n",
      "\n",
      "       [[155, 153, 159],\n",
      "        [162, 160, 166],\n",
      "        [161, 159, 165],\n",
      "        ...,\n",
      "        [112, 115, 123],\n",
      "        [153, 156, 164],\n",
      "        [137, 140, 148]],\n",
      "\n",
      "       [[150, 148, 154],\n",
      "        [146, 144, 150],\n",
      "        [173, 171, 177],\n",
      "        ...,\n",
      "        [111, 114, 122],\n",
      "        [144, 147, 155],\n",
      "        [152, 155, 163]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[151, 147, 142],\n",
      "        [181, 177, 172],\n",
      "        [208, 204, 199],\n",
      "        ...,\n",
      "        [203, 196, 211],\n",
      "        [169, 162, 177],\n",
      "        [165, 158, 173]],\n",
      "\n",
      "       [[104, 100,  95],\n",
      "        [139, 135, 130],\n",
      "        [205, 201, 196],\n",
      "        ...,\n",
      "        [207, 200, 215],\n",
      "        [178, 170, 187],\n",
      "        [165, 157, 174]],\n",
      "\n",
      "       [[ 75,  71,  66],\n",
      "        [118, 114, 109],\n",
      "        [133, 129, 124],\n",
      "        ...,\n",
      "        [198, 191, 206],\n",
      "        [184, 176, 193],\n",
      "        [172, 164, 181]]], dtype=uint8)\n",
      "orig_shape: (640, 640)\n",
      "path: '/content/datasets/fruit-spoil-detection-1/test/images/frame_0001_jpg.rf.633cc298dfd9fe8c050e106f18c84578.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs/segment/predict'\n",
      "speed: {'preprocess': 3.4513473510742188, 'inference': 49.31068420410156, 'postprocess': 11.021614074707031}\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'fresh', 1: 'spoiled'}\n",
      "orig_img: array([[[151, 149, 155],\n",
      "        [136, 134, 140],\n",
      "        [175, 173, 179],\n",
      "        ...,\n",
      "        [103, 107, 112],\n",
      "        [ 88,  92,  97],\n",
      "        [ 87,  91,  96]],\n",
      "\n",
      "       [[149, 147, 153],\n",
      "        [129, 127, 133],\n",
      "        [151, 149, 155],\n",
      "        ...,\n",
      "        [ 95,  99, 104],\n",
      "        [ 93,  97, 102],\n",
      "        [ 93,  97, 102]],\n",
      "\n",
      "       [[145, 143, 149],\n",
      "        [163, 161, 167],\n",
      "        [168, 166, 172],\n",
      "        ...,\n",
      "        [ 93,  97, 102],\n",
      "        [ 91,  95, 100],\n",
      "        [ 82,  86,  91]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[158, 155, 147],\n",
      "        [110, 107,  99],\n",
      "        [202, 199, 191],\n",
      "        ...,\n",
      "        [114, 112, 112],\n",
      "        [125, 123, 122],\n",
      "        [114, 112, 111]],\n",
      "\n",
      "       [[150, 147, 139],\n",
      "        [151, 148, 140],\n",
      "        [191, 188, 180],\n",
      "        ...,\n",
      "        [105, 103, 103],\n",
      "        [118, 116, 115],\n",
      "        [116, 115, 111]],\n",
      "\n",
      "       [[138, 135, 127],\n",
      "        [122, 119, 111],\n",
      "        [125, 122, 114],\n",
      "        ...,\n",
      "        [ 91,  89,  88],\n",
      "        [101,  99,  98],\n",
      "        [101, 100,  96]]], dtype=uint8)\n",
      "orig_shape: (640, 640)\n",
      "path: '/content/datasets/fruit-spoil-detection-1/test/images/frame_0003_jpg.rf.32f2035a05a361a52160107e11708e55.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs/segment/predict'\n",
      "speed: {'preprocess': 3.6840438842773438, 'inference': 39.06440734863281, 'postprocess': 6.485462188720703}\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'fresh', 1: 'spoiled'}\n",
      "orig_img: array([[[178, 172, 191],\n",
      "        [172, 166, 185],\n",
      "        [180, 174, 193],\n",
      "        ...,\n",
      "        [ 80,  85,  86],\n",
      "        [ 62,  67,  68],\n",
      "        [ 58,  63,  64]],\n",
      "\n",
      "       [[174, 168, 187],\n",
      "        [179, 173, 192],\n",
      "        [163, 157, 176],\n",
      "        ...,\n",
      "        [ 78,  83,  84],\n",
      "        [ 53,  58,  59],\n",
      "        [ 35,  40,  41]],\n",
      "\n",
      "       [[172, 166, 183],\n",
      "        [156, 150, 167],\n",
      "        [140, 134, 151],\n",
      "        ...,\n",
      "        [ 85,  90,  91],\n",
      "        [ 71,  76,  77],\n",
      "        [ 50,  55,  56]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[118, 113, 110],\n",
      "        [104,  99,  96],\n",
      "        [106, 102,  97],\n",
      "        ...,\n",
      "        [113, 112, 114],\n",
      "        [124, 123, 125],\n",
      "        [120, 119, 121]],\n",
      "\n",
      "       [[135, 130, 127],\n",
      "        [ 98,  93,  90],\n",
      "        [ 92,  87,  84],\n",
      "        ...,\n",
      "        [100,  99, 101],\n",
      "        [114, 113, 115],\n",
      "        [118, 117, 119]],\n",
      "\n",
      "       [[176, 171, 168],\n",
      "        [113, 108, 105],\n",
      "        [ 80,  75,  72],\n",
      "        ...,\n",
      "        [ 86,  85,  87],\n",
      "        [100,  99, 101],\n",
      "        [108, 107, 109]]], dtype=uint8)\n",
      "orig_shape: (640, 640)\n",
      "path: '/content/datasets/fruit-spoil-detection-1/test/images/frame_0006_jpg.rf.5fc834bf7cbd52c8a739a5ed69b34e37.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs/segment/predict'\n",
      "speed: {'preprocess': 2.771615982055664, 'inference': 38.71464729309082, 'postprocess': 6.336688995361328}\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'fresh', 1: 'spoiled'}\n",
      "orig_img: array([[[132, 128, 133],\n",
      "        [172, 168, 173],\n",
      "        [144, 140, 145],\n",
      "        ...,\n",
      "        [102, 108, 107],\n",
      "        [103, 109, 108],\n",
      "        [102, 108, 107]],\n",
      "\n",
      "       [[133, 129, 134],\n",
      "        [169, 165, 170],\n",
      "        [151, 147, 152],\n",
      "        ...,\n",
      "        [ 80,  86,  85],\n",
      "        [ 94, 100,  99],\n",
      "        [109, 115, 114]],\n",
      "\n",
      "       [[161, 157, 162],\n",
      "        [164, 160, 165],\n",
      "        [148, 144, 149],\n",
      "        ...,\n",
      "        [ 70,  76,  75],\n",
      "        [ 85,  91,  90],\n",
      "        [102, 108, 107]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 77,  75,  65],\n",
      "        [130, 128, 118],\n",
      "        [103, 101,  91],\n",
      "        ...,\n",
      "        [107, 106, 110],\n",
      "        [114, 113, 117],\n",
      "        [111, 110, 114]],\n",
      "\n",
      "       [[122, 120, 110],\n",
      "        [173, 171, 161],\n",
      "        [ 95,  93,  83],\n",
      "        ...,\n",
      "        [ 98,  97, 101],\n",
      "        [115, 114, 118],\n",
      "        [115, 114, 118]],\n",
      "\n",
      "       [[141, 139, 129],\n",
      "        [150, 148, 138],\n",
      "        [114, 112, 102],\n",
      "        ...,\n",
      "        [ 96,  95,  99],\n",
      "        [116, 115, 119],\n",
      "        [116, 115, 119]]], dtype=uint8)\n",
      "orig_shape: (640, 640)\n",
      "path: '/content/datasets/fruit-spoil-detection-1/test/images/frame_0010_jpg.rf.b8a04b4f7c4f6c731cc72b9644de6d3a.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs/segment/predict'\n",
      "speed: {'preprocess': 2.1724700927734375, 'inference': 35.9804630279541, 'postprocess': 6.116628646850586}\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'fresh', 1: 'spoiled'}\n",
      "orig_img: array([[[135, 131, 136],\n",
      "        [138, 134, 139],\n",
      "        [141, 137, 142],\n",
      "        ...,\n",
      "        [151, 162, 160],\n",
      "        [149, 160, 158],\n",
      "        [146, 157, 155]],\n",
      "\n",
      "       [[174, 170, 175],\n",
      "        [176, 172, 177],\n",
      "        [165, 161, 166],\n",
      "        ...,\n",
      "        [154, 165, 163],\n",
      "        [150, 161, 159],\n",
      "        [140, 151, 149]],\n",
      "\n",
      "       [[199, 195, 200],\n",
      "        [201, 197, 202],\n",
      "        [180, 176, 181],\n",
      "        ...,\n",
      "        [154, 165, 163],\n",
      "        [154, 165, 163],\n",
      "        [140, 151, 149]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[131, 126, 125],\n",
      "        [110, 105, 104],\n",
      "        [112, 107, 106],\n",
      "        ...,\n",
      "        [ 94,  92,  92],\n",
      "        [ 86,  81,  82],\n",
      "        [ 82,  77,  78]],\n",
      "\n",
      "       [[ 86,  81,  80],\n",
      "        [ 96,  91,  90],\n",
      "        [108, 103, 102],\n",
      "        ...,\n",
      "        [107, 105, 105],\n",
      "        [ 89,  84,  85],\n",
      "        [ 76,  71,  72]],\n",
      "\n",
      "       [[117, 112, 111],\n",
      "        [161, 156, 155],\n",
      "        [158, 153, 152],\n",
      "        ...,\n",
      "        [140, 138, 138],\n",
      "        [108, 103, 104],\n",
      "        [ 78,  73,  74]]], dtype=uint8)\n",
      "orig_shape: (640, 640)\n",
      "path: '/content/datasets/fruit-spoil-detection-1/test/images/frame_0011_jpg.rf.92590df2f8ad2472d3e950efe37c2014.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs/segment/predict'\n",
      "speed: {'preprocess': 3.6182403564453125, 'inference': 36.16619110107422, 'postprocess': 7.388830184936523}\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'fresh', 1: 'spoiled'}\n",
      "orig_img: array([[[153, 153, 165],\n",
      "        [171, 171, 183],\n",
      "        [159, 159, 171],\n",
      "        ...,\n",
      "        [129, 131, 132],\n",
      "        [125, 127, 128],\n",
      "        [116, 118, 119]],\n",
      "\n",
      "       [[155, 155, 167],\n",
      "        [171, 171, 183],\n",
      "        [146, 146, 158],\n",
      "        ...,\n",
      "        [131, 133, 134],\n",
      "        [117, 119, 120],\n",
      "        [ 98, 100, 101]],\n",
      "\n",
      "       [[152, 152, 164],\n",
      "        [180, 180, 192],\n",
      "        [164, 164, 176],\n",
      "        ...,\n",
      "        [135, 137, 138],\n",
      "        [123, 125, 126],\n",
      "        [105, 107, 108]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[143, 138, 123],\n",
      "        [130, 125, 110],\n",
      "        [195, 190, 175],\n",
      "        ...,\n",
      "        [104, 101,  97],\n",
      "        [109, 105, 100],\n",
      "        [113, 109, 104]],\n",
      "\n",
      "       [[153, 148, 133],\n",
      "        [126, 121, 106],\n",
      "        [168, 163, 148],\n",
      "        ...,\n",
      "        [114, 111, 107],\n",
      "        [122, 118, 113],\n",
      "        [114, 110, 105]],\n",
      "\n",
      "       [[166, 161, 146],\n",
      "        [131, 126, 111],\n",
      "        [146, 141, 126],\n",
      "        ...,\n",
      "        [144, 141, 137],\n",
      "        [158, 154, 149],\n",
      "        [126, 122, 117]]], dtype=uint8)\n",
      "orig_shape: (640, 640)\n",
      "path: '/content/datasets/fruit-spoil-detection-1/test/images/frame_0043_jpg.rf.9fce5495d416466ab7531d630e167ecd.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs/segment/predict'\n",
      "speed: {'preprocess': 2.2928714752197266, 'inference': 35.552024841308594, 'postprocess': 7.497549057006836}\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'fresh', 1: 'spoiled'}\n",
      "orig_img: array([[[ 89,  89, 101],\n",
      "        [117, 117, 129],\n",
      "        [159, 159, 171],\n",
      "        ...,\n",
      "        [116, 118, 119],\n",
      "        [135, 137, 138],\n",
      "        [127, 129, 130]],\n",
      "\n",
      "       [[114, 114, 126],\n",
      "        [112, 112, 124],\n",
      "        [145, 145, 157],\n",
      "        ...,\n",
      "        [145, 147, 148],\n",
      "        [135, 137, 138],\n",
      "        [160, 162, 163]],\n",
      "\n",
      "       [[139, 139, 151],\n",
      "        [124, 124, 136],\n",
      "        [148, 148, 160],\n",
      "        ...,\n",
      "        [135, 137, 138],\n",
      "        [134, 136, 137],\n",
      "        [161, 163, 164]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[154, 149, 134],\n",
      "        [139, 134, 119],\n",
      "        [144, 139, 124],\n",
      "        ...,\n",
      "        [112, 110, 110],\n",
      "        [134, 132, 132],\n",
      "        [121, 119, 118]],\n",
      "\n",
      "       [[160, 155, 140],\n",
      "        [127, 122, 107],\n",
      "        [118, 113,  98],\n",
      "        ...,\n",
      "        [129, 127, 127],\n",
      "        [117, 115, 115],\n",
      "        [114, 112, 112]],\n",
      "\n",
      "       [[196, 191, 176],\n",
      "        [151, 146, 131],\n",
      "        [119, 114,  99],\n",
      "        ...,\n",
      "        [149, 146, 148],\n",
      "        [123, 121, 121],\n",
      "        [132, 130, 130]]], dtype=uint8)\n",
      "orig_shape: (640, 640)\n",
      "path: '/content/datasets/fruit-spoil-detection-1/test/images/frame_0047_jpg.rf.5bd4e80a96798e11f317da19900f0673.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs/segment/predict'\n",
      "speed: {'preprocess': 4.304409027099609, 'inference': 28.268814086914062, 'postprocess': 7.99870491027832}\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'fresh', 1: 'spoiled'}\n",
      "orig_img: array([[[143, 140, 156],\n",
      "        [150, 147, 163],\n",
      "        [146, 143, 159],\n",
      "        ...,\n",
      "        [127, 130, 135],\n",
      "        [122, 125, 130],\n",
      "        [118, 121, 126]],\n",
      "\n",
      "       [[166, 163, 179],\n",
      "        [158, 155, 171],\n",
      "        [141, 138, 154],\n",
      "        ...,\n",
      "        [121, 124, 129],\n",
      "        [113, 116, 121],\n",
      "        [109, 112, 117]],\n",
      "\n",
      "       [[140, 137, 153],\n",
      "        [140, 137, 153],\n",
      "        [140, 137, 153],\n",
      "        ...,\n",
      "        [113, 116, 121],\n",
      "        [108, 111, 116],\n",
      "        [107, 110, 115]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[157, 151, 138],\n",
      "        [122, 116, 103],\n",
      "        [ 93,  87,  74],\n",
      "        ...,\n",
      "        [162, 160, 152],\n",
      "        [155, 154, 144],\n",
      "        [148, 147, 137]],\n",
      "\n",
      "       [[121, 115, 102],\n",
      "        [107, 101,  88],\n",
      "        [ 92,  86,  73],\n",
      "        ...,\n",
      "        [159, 157, 147],\n",
      "        [152, 150, 140],\n",
      "        [145, 143, 133]],\n",
      "\n",
      "       [[129, 123, 110],\n",
      "        [132, 126, 113],\n",
      "        [119, 113, 100],\n",
      "        ...,\n",
      "        [155, 153, 143],\n",
      "        [148, 146, 136],\n",
      "        [141, 139, 129]]], dtype=uint8)\n",
      "orig_shape: (640, 640)\n",
      "path: '/content/datasets/fruit-spoil-detection-1/test/images/frame_0052_jpg.rf.a309d352f2feac43ab5e2602aa4fa0ae.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs/segment/predict'\n",
      "speed: {'preprocess': 3.6172866821289062, 'inference': 26.213884353637695, 'postprocess': 7.6351165771484375}\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'fresh', 1: 'spoiled'}\n",
      "orig_img: array([[[137, 136, 140],\n",
      "        [135, 134, 138],\n",
      "        [143, 142, 146],\n",
      "        ...,\n",
      "        [176, 177, 181],\n",
      "        [179, 180, 184],\n",
      "        [182, 183, 187]],\n",
      "\n",
      "       [[147, 146, 150],\n",
      "        [135, 134, 138],\n",
      "        [131, 130, 134],\n",
      "        ...,\n",
      "        [173, 174, 178],\n",
      "        [174, 175, 179],\n",
      "        [176, 177, 181]],\n",
      "\n",
      "       [[137, 136, 140],\n",
      "        [127, 126, 130],\n",
      "        [126, 125, 129],\n",
      "        ...,\n",
      "        [175, 176, 180],\n",
      "        [174, 175, 179],\n",
      "        [174, 175, 179]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 89,  83,  70],\n",
      "        [ 88,  82,  69],\n",
      "        [ 90,  84,  71],\n",
      "        ...,\n",
      "        [115, 133, 126],\n",
      "        [125, 142, 133],\n",
      "        [129, 146, 137]],\n",
      "\n",
      "       [[ 89,  83,  70],\n",
      "        [ 90,  84,  71],\n",
      "        [ 94,  88,  75],\n",
      "        ...,\n",
      "        [117, 133, 126],\n",
      "        [123, 140, 131],\n",
      "        [127, 144, 135]],\n",
      "\n",
      "       [[ 94,  88,  75],\n",
      "        [ 95,  89,  76],\n",
      "        [ 97,  91,  78],\n",
      "        ...,\n",
      "        [111, 127, 120],\n",
      "        [116, 133, 124],\n",
      "        [127, 144, 135]]], dtype=uint8)\n",
      "orig_shape: (640, 640)\n",
      "path: '/content/datasets/fruit-spoil-detection-1/test/images/frame_0078_jpg.rf.2b82af13d1b56e46ae541b75290aaca2.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs/segment/predict'\n",
      "speed: {'preprocess': 4.030466079711914, 'inference': 26.594161987304688, 'postprocess': 6.831884384155273}\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'fresh', 1: 'spoiled'}\n",
      "orig_img: array([[[170, 170, 170],\n",
      "        [162, 162, 162],\n",
      "        [134, 134, 134],\n",
      "        ...,\n",
      "        [ 98, 103, 104],\n",
      "        [106, 111, 112],\n",
      "        [ 77,  82,  83]],\n",
      "\n",
      "       [[180, 180, 180],\n",
      "        [157, 157, 157],\n",
      "        [163, 163, 163],\n",
      "        ...,\n",
      "        [ 82,  87,  88],\n",
      "        [ 97, 102, 103],\n",
      "        [ 96, 101, 102]],\n",
      "\n",
      "       [[184, 184, 184],\n",
      "        [138, 138, 138],\n",
      "        [153, 153, 153],\n",
      "        ...,\n",
      "        [ 72,  77,  78],\n",
      "        [ 90,  98,  98],\n",
      "        [104, 112, 112]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 96,  94,  94],\n",
      "        [ 82,  80,  80],\n",
      "        [ 97,  95,  95],\n",
      "        ...,\n",
      "        [134, 152, 145],\n",
      "        [132, 150, 143],\n",
      "        [119, 137, 130]],\n",
      "\n",
      "       [[102, 100, 100],\n",
      "        [119, 117, 117],\n",
      "        [100,  98,  98],\n",
      "        ...,\n",
      "        [138, 156, 149],\n",
      "        [160, 178, 171],\n",
      "        [144, 162, 155]],\n",
      "\n",
      "       [[103, 101, 101],\n",
      "        [155, 153, 153],\n",
      "        [105, 103, 103],\n",
      "        ...,\n",
      "        [135, 153, 146],\n",
      "        [184, 202, 195],\n",
      "        [169, 187, 180]]], dtype=uint8)\n",
      "orig_shape: (640, 640)\n",
      "path: '/content/datasets/fruit-spoil-detection-1/test/images/frame_0086_jpg.rf.a5986d6b56f3441a2047b5e5797feb04.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs/segment/predict'\n",
      "speed: {'preprocess': 3.885507583618164, 'inference': 26.203393936157227, 'postprocess': 8.340597152709961}\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'fresh', 1: 'spoiled'}\n",
      "orig_img: array([[[112, 111, 113],\n",
      "        [141, 140, 142],\n",
      "        [173, 172, 174],\n",
      "        ...,\n",
      "        [133, 141, 141],\n",
      "        [163, 171, 171],\n",
      "        [151, 159, 159]],\n",
      "\n",
      "       [[162, 161, 163],\n",
      "        [108, 107, 109],\n",
      "        [150, 149, 151],\n",
      "        ...,\n",
      "        [135, 143, 143],\n",
      "        [132, 140, 140],\n",
      "        [127, 135, 135]],\n",
      "\n",
      "       [[187, 186, 188],\n",
      "        [114, 113, 115],\n",
      "        [138, 137, 139],\n",
      "        ...,\n",
      "        [143, 151, 151],\n",
      "        [108, 116, 116],\n",
      "        [113, 121, 121]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[144, 139, 140],\n",
      "        [ 97,  92,  93],\n",
      "        [ 76,  71,  72],\n",
      "        ...,\n",
      "        [148, 150, 161],\n",
      "        [144, 146, 157],\n",
      "        [133, 135, 146]],\n",
      "\n",
      "       [[134, 129, 130],\n",
      "        [106, 101, 102],\n",
      "        [104,  99, 100],\n",
      "        ...,\n",
      "        [158, 160, 171],\n",
      "        [153, 155, 166],\n",
      "        [170, 172, 183]],\n",
      "\n",
      "       [[127, 122, 123],\n",
      "        [111, 106, 107],\n",
      "        [126, 121, 122],\n",
      "        ...,\n",
      "        [144, 146, 157],\n",
      "        [133, 135, 146],\n",
      "        [180, 182, 193]]], dtype=uint8)\n",
      "orig_shape: (640, 640)\n",
      "path: '/content/datasets/fruit-spoil-detection-1/test/images/frame_0099_jpg.rf.358744d766386ce0e596ebf5b0f0e933.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs/segment/predict'\n",
      "speed: {'preprocess': 7.205963134765625, 'inference': 24.05548095703125, 'postprocess': 6.829261779785156}\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'fresh', 1: 'spoiled'}\n",
      "orig_img: array([[[ 90,  95,  98],\n",
      "        [ 85,  90,  93],\n",
      "        [ 80,  85,  88],\n",
      "        ...,\n",
      "        [110, 113, 127],\n",
      "        [115, 119, 130],\n",
      "        [122, 126, 137]],\n",
      "\n",
      "       [[ 85,  90,  93],\n",
      "        [ 82,  87,  90],\n",
      "        [ 78,  83,  86],\n",
      "        ...,\n",
      "        [112, 115, 129],\n",
      "        [111, 115, 126],\n",
      "        [113, 117, 128]],\n",
      "\n",
      "       [[ 81,  86,  89],\n",
      "        [ 79,  84,  87],\n",
      "        [ 78,  83,  86],\n",
      "        ...,\n",
      "        [117, 120, 134],\n",
      "        [113, 117, 128],\n",
      "        [113, 117, 128]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 99, 100,  91],\n",
      "        [100, 101,  92],\n",
      "        [104, 105,  96],\n",
      "        ...,\n",
      "        [ 86,  86,  80],\n",
      "        [ 85,  85,  79],\n",
      "        [ 85,  85,  79]],\n",
      "\n",
      "       [[ 98,  99,  90],\n",
      "        [ 98,  99,  90],\n",
      "        [100, 101,  92],\n",
      "        ...,\n",
      "        [ 88,  88,  82],\n",
      "        [ 86,  86,  80],\n",
      "        [ 83,  83,  77]],\n",
      "\n",
      "       [[102, 103,  94],\n",
      "        [102, 103,  94],\n",
      "        [103, 104,  95],\n",
      "        ...,\n",
      "        [ 83,  83,  77],\n",
      "        [ 82,  82,  76],\n",
      "        [ 81,  81,  75]]], dtype=uint8)\n",
      "orig_shape: (640, 640)\n",
      "path: '/content/datasets/fruit-spoil-detection-1/test/images/frame_0119_jpg.rf.58f0fc67757b4bd5640e1b31fc4a888c.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs/segment/predict'\n",
      "speed: {'preprocess': 5.472898483276367, 'inference': 23.870229721069336, 'postprocess': 7.591009140014648}\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'fresh', 1: 'spoiled'}\n",
      "orig_img: array([[[173, 174, 178],\n",
      "        [171, 172, 176],\n",
      "        [168, 169, 173],\n",
      "        ...,\n",
      "        [101, 103, 113],\n",
      "        [110, 112, 122],\n",
      "        [119, 121, 131]],\n",
      "\n",
      "       [[173, 174, 178],\n",
      "        [172, 173, 177],\n",
      "        [168, 169, 173],\n",
      "        ...,\n",
      "        [ 96,  98, 108],\n",
      "        [101, 103, 113],\n",
      "        [107, 109, 119]],\n",
      "\n",
      "       [[157, 158, 162],\n",
      "        [159, 160, 164],\n",
      "        [160, 161, 165],\n",
      "        ...,\n",
      "        [ 90,  92, 102],\n",
      "        [ 92,  94, 104],\n",
      "        [ 98, 100, 110]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[108, 108,  94],\n",
      "        [108, 108,  94],\n",
      "        [122, 122, 108],\n",
      "        ...,\n",
      "        [111, 109, 109],\n",
      "        [105, 103, 103],\n",
      "        [ 98,  96,  96]],\n",
      "\n",
      "       [[ 96,  96,  82],\n",
      "        [100, 100,  86],\n",
      "        [117, 117, 103],\n",
      "        ...,\n",
      "        [116, 114, 114],\n",
      "        [108, 106, 106],\n",
      "        [ 99,  97,  97]],\n",
      "\n",
      "       [[102, 102,  88],\n",
      "        [106, 106,  92],\n",
      "        [121, 121, 107],\n",
      "        ...,\n",
      "        [125, 123, 123],\n",
      "        [123, 121, 121],\n",
      "        [117, 115, 115]]], dtype=uint8)\n",
      "orig_shape: (640, 640)\n",
      "path: '/content/datasets/fruit-spoil-detection-1/test/images/frame_0125_jpg.rf.224506015b0821fbc7e1936be67d1d6f.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs/segment/predict'\n",
      "speed: {'preprocess': 5.274057388305664, 'inference': 24.236202239990234, 'postprocess': 7.654905319213867}\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Set up paths\n",
    "home_dir = \"/content/datasets\"\n",
    "model_path = os.path.join(home_dir, \"runs/segment/train/weights/best.pt\")\n",
    "image_dir = os.path.join(\"/content/datasets/fruit-spoil-detection-1\", \"test/images\")\n",
    "\n",
    "# Load the model\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Run prediction\n",
    "results = model.predict(source=image_dir, conf=0.25, save=True)\n",
    "\n",
    "# If you need to access the output, you can iterate through results\n",
    "for result in results:\n",
    "    print(result)  # or save, or visualize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "JwxwakID6vqh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "hJhI5Oef6xIw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "bvr1wU2B5w5V"
   },
   "outputs": [],
   "source": [
    "#!ls -ltr /content/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dw4FgTrC5fGM",
    "outputId": "f9c6ebc9-a5e0-4275-e10e-a67f64dffbdb"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for image_path in glob.glob(f'runs/segment/predict/*.jpg'):\n",
    "      print(image_path)\n",
    "      display(Image(filename=image_path, height=600))\n",
    "      print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lq5LwnH5wTw"
   },
   "source": [
    "![spoil_prediction_1](spoil_prediction_1.png)\n",
    "\n",
    "![spoil_prediction_2](spoil_prediction_2.png)\n",
    "\n",
    "![spoil_prediction_3](spoil_prediction_3.png)\n",
    "\n",
    "![spoil_prediction_4](spoil_prediction_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jz4PuxNo6yRu"
   },
   "source": [
    "![spoil_with_mask_1](spoil_with_mask_1.png)\n",
    "\n",
    "![spoil_with_mask_2](spoil_with_mask_2.png)\n",
    "\n",
    "![spoil_with_mask_3](spoil_with_mask_3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RV6m_LP1fgBO"
   },
   "source": [
    "# Step 7. Visualize masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mu9dLGV16yXV",
    "outputId": "8be022da-b7c5-4887-e27f-7efec9e53b7e"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Assuming `results` is a list of `Results` objects from the YOLO model prediction\n",
    "\n",
    "for result in results:\n",
    "    # Load the original image\n",
    "    img = cv2.imread(result.path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display the original image\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title(\"Original Image with Bounding Boxes\")\n",
    "\n",
    "    # Draw bounding boxes\n",
    "    for box in result.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        label = result.names[int(box.cls)]\n",
    "        cv2.rectangle(img_rgb, (x1, y1), (x2, y2), color=(255, 0, 0), thickness=2)\n",
    "        cv2.putText(img_rgb, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    plt.imshow(img_rgb)\n",
    "\n",
    "    # Display the mask on the original image\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img_rgb)\n",
    "    for mask in result.masks.data:\n",
    "        mask = mask.cpu().numpy()\n",
    "        plt.imshow(mask, alpha=0.5, cmap='jet')  # Overlay the mask on the image\n",
    "\n",
    "    plt.title(\"Image with Masks\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "9_55tOZJ66Fy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "k_mqVj1H7vkw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5R3ugkkE7_BP",
    "outputId": "46956c97-9bfc-4a3f-aab7-ec504ab9dd8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1WjtfsOw7vno",
    "outputId": "472721d2-27b9-429a-f6d4-4f8a135a88ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /content/drive/My Drive/Colab Notebooks/spoiled_fruit_test1.jpg: 640x480 2 freshs, 172.8ms\n",
      "Speed: 4.7ms preprocess, 172.8ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mruns/segment/predict2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up paths\n",
    "model_path = \"/content/datasets/runs/segment/train/weights/best.pt\"\n",
    "image_path = \"/content/drive/My Drive/Colab Notebooks/spoiled_fruit_test1.jpg\"\n",
    "output_image_path = \"/content/new_test_img_with_results.jpg\"\n",
    "\n",
    "# Load the model\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Run prediction\n",
    "results = model.predict(source=image_path, conf=0.25, save=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "CO2BtNqk--cR",
    "outputId": "821f4621-6f14-4746-a489-bcc58df3e127"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for image_path in glob.glob(f'runs/segment/predict2/*.jpg'):\n",
    "      print(image_path)\n",
    "      display(Image(filename=image_path, height=600))\n",
    "      print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "PdRNBAgT-9We",
    "outputId": "3889fc8b-fd4f-4371-898d-4bb4b2064c21"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "for result in results:\n",
    "    # Load the original image\n",
    "    img = cv2.imread(result.path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Lighten the background image\n",
    "    img_rgb = cv2.convertScaleAbs(img_rgb, alpha=1.5, beta=50)  # Increase brightness\n",
    "\n",
    "    # Display the original image with bounding boxes\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title(\"Original Image with Bounding Boxes\")\n",
    "\n",
    "    # Draw bounding boxes\n",
    "    for box in result.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        label = result.names[int(box.cls)]\n",
    "        confidence = box.conf[0]\n",
    "        cv2.rectangle(img_rgb, (x1, y1), (x2, y2), color=(255, 0, 0), thickness=2)\n",
    "        cv2.putText(img_rgb, f'{label} {confidence:.2f}', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    plt.imshow(img_rgb)\n",
    "\n",
    "    # Display the mask on the lightened image\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img_rgb)\n",
    "    for mask in result.masks.data:\n",
    "        mask = mask.cpu().numpy()\n",
    "        plt.imshow(mask, alpha=0.5, cmap='jet')  # Overlay the mask on the image\n",
    "\n",
    "    plt.title(\"Image with Masks\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![spoil_with_mask_4](spoil_with_mask_4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "3JLFZ1MABkoD",
    "outputId": "61bf82e1-ff32-43dc-b195-32d5bf9113ab"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "for result in results:\n",
    "    # Load the original image\n",
    "    img = cv2.imread(result.path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display the original image with bounding boxes\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title(\"Original Image with Bounding Boxes\")\n",
    "\n",
    "    # # Draw bounding boxes\n",
    "    # for box in result.boxes:\n",
    "    #     x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "    #     label = result.names[int(box.cls)]\n",
    "    #     confidence = box.conf[0]\n",
    "    #     cv2.rectangle(img_rgb, (x1, y1), (x2, y2), color=(255, 0, 0), thickness=2)\n",
    "    #     cv2.putText(img_rgb, f'{label} {confidence:.2f}', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "        # Draw bounding boxes\n",
    "    for box in result.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        label = result.names[int(box.cls)]\n",
    "        confidence = box.conf[0]\n",
    "        cv2.rectangle(img_rgb, (x1, y1), (x2, y2), color=(255, 0, 0), thickness=2)\n",
    "        cv2.putText(img_rgb, f'{label} {confidence:.2f}', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    plt.imshow(img_rgb)\n",
    "\n",
    "    # Prepare to display masks\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img_rgb)  # Display the original image for mask overlay\n",
    "    plt.title(\"Image with Masks\")\n",
    "\n",
    "    # Overlay masks\n",
    "    for mask in result.masks.data:\n",
    "        mask = mask.cpu().numpy()\n",
    "        # Resize mask to match the image dimensions\n",
    "        mask_resized = cv2.resize(mask, (img_rgb.shape[1], img_rgb.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "        # Apply color map\n",
    "        mask_colored = cv2.applyColorMap((mask_resized * 255).astype(np.uint8), cv2.COLORMAP_SPRING)\n",
    "        # Blend the mask with the image\n",
    "        img_with_mask = cv2.addWeighted(img_rgb, 1, mask_colored, 0.6, 0)  # Adjust alpha for visibility\n",
    "\n",
    "    plt.imshow(img_with_mask)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![spoil_with_mask_5](spoil_with_mask_5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Nl7Fnl0gArXD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "MNrVnIkUAram"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBwHbxxWArd_",
    "outputId": "5996bd46-f733-4969-bdb5-b4f84733f696"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /content/drive/My Drive/Colab Notebooks/spoiled_fruit_test2.jpg: 480x640 2 spoileds, 93.5ms\n",
      "Speed: 3.2ms preprocess, 93.5ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up paths\n",
    "model_path = \"/content/datasets/runs/segment/train/weights/best.pt\"\n",
    "image_path = \"/content/drive/My Drive/Colab Notebooks/spoiled_fruit_test2.jpg\"\n",
    "output_image_path = \"/content/new_test_img_with_results.jpg\"\n",
    "\n",
    "# Load the model\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Run prediction\n",
    "results = model.predict(source=image_path, conf=0.25, save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "grpIIswgAuq2",
    "outputId": "e7f62aeb-59fa-4cbb-9648-af18d619aeef"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for image_path in glob.glob(f'runs/segment/predict3/*.jpg'):\n",
    "      print(image_path)\n",
    "      display(Image(filename=image_path, height=600))\n",
    "      print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![spoil_fruit_test_2](spoil_fruit_test_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "a2A7UpsiC7XK",
    "outputId": "448ae099-d174-4cdc-e7d2-c7c4b704de98"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "for result in results:\n",
    "    # Load the original image\n",
    "    img = cv2.imread(result.path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Lighten the background image\n",
    "    img_rgb = cv2.convertScaleAbs(img_rgb, alpha=1.5, beta=50)  # Increase brightness\n",
    "\n",
    "    # Display the original image with bounding boxes\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title(\"Original Image with Bounding Boxes\")\n",
    "\n",
    "    # Draw bounding boxes\n",
    "    for box in result.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        label = result.names[int(box.cls)]\n",
    "        confidence = box.conf[0]\n",
    "        cv2.rectangle(img_rgb, (x1, y1), (x2, y2), color=(255, 0, 0), thickness=2)\n",
    "        cv2.putText(img_rgb, f'{label} {confidence:.2f}', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    plt.imshow(img_rgb)\n",
    "\n",
    "    # Display the mask on the lightened image\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img_rgb)\n",
    "    for mask in result.masks.data:\n",
    "        mask = mask.cpu().numpy()\n",
    "        plt.imshow(mask, alpha=0.5, cmap='jet')  # Overlay the mask on the image\n",
    "\n",
    "    plt.title(\"Image with Masks\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![spoil_fruit_test_2](spoil_fruit_test_2_mask.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "CMKug3BvDR6i"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vIgFfgnjWb7B",
    "outputId": "13242653-d19e-412a-cd1b-cf885bf38b3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /content/drive/My Drive/Colab Notebooks/spoiled_fruit_test3.jpg: 480x640 2 freshs, 1 spoiled, 39.5ms\n",
      "Speed: 3.1ms preprocess, 39.5ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns/segment/predict4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up paths\n",
    "model_path = \"/content/datasets/runs/segment/train/weights/best.pt\"\n",
    "image_path = \"/content/drive/My Drive/Colab Notebooks/spoiled_fruit_test3.jpg\"\n",
    "output_image_path = \"/content/new_test_img_with_results.jpg\"\n",
    "\n",
    "# Load the model\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Run prediction\n",
    "results = model.predict(source=image_path, conf=0.25, save=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "ymx4l5CVWb-I",
    "outputId": "573ca813-cb1a-4efd-83b7-2ae8738da815"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for image_path in glob.glob(f'runs/segment/predict4/*.jpg'):\n",
    "      print(image_path)\n",
    "      display(Image(filename=image_path, height=600))\n",
    "      print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![spoiled_fruit_test3](spoiled_fruit_test3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "dV3uJaccWo-9",
    "outputId": "471ee5f5-eb68-4c35-ad4e-33472a9a6835"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "for result in results:\n",
    "    # Load the original image\n",
    "    img = cv2.imread(result.path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Lighten the background image\n",
    "    img_rgb = cv2.convertScaleAbs(img_rgb, alpha=1.5, beta=50)  # Increase brightness\n",
    "\n",
    "    # Display the original image with bounding boxes\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title(\"Original Image with Bounding Boxes\")\n",
    "\n",
    "    # Draw bounding boxes\n",
    "    for box in result.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        label = result.names[int(box.cls)]\n",
    "        confidence = box.conf[0]\n",
    "        cv2.rectangle(img_rgb, (x1, y1), (x2, y2), color=(255, 0, 0), thickness=2)\n",
    "        cv2.putText(img_rgb, f'{label} {confidence:.2f}', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    plt.imshow(img_rgb)\n",
    "\n",
    "    # Display the mask on the lightened image\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img_rgb)\n",
    "    for mask in result.masks.data:\n",
    "        mask = mask.cpu().numpy()\n",
    "        plt.imshow(mask, alpha=0.5, cmap='jet')  # Overlay the mask on the image\n",
    "\n",
    "    plt.title(\"Image with Masks\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![spoiled_fruit_test3](spoiled_fruit_test3_mask.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "leoPWChiWrik",
    "outputId": "be9c45bf-4604-4d59-8058-d8a1b6f06ca7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "for result in results:\n",
    "    # Load the original image\n",
    "    img = cv2.imread(result.path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display the original image with bounding boxes\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title(\"Original Image with Bounding Boxes\")\n",
    "\n",
    "    # # Draw bounding boxes\n",
    "    # for box in result.boxes:\n",
    "    #     x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "    #     label = result.names[int(box.cls)]\n",
    "    #     confidence = box.conf[0]\n",
    "    #     cv2.rectangle(img_rgb, (x1, y1), (x2, y2), color=(255, 0, 0), thickness=2)\n",
    "    #     cv2.putText(img_rgb, f'{label} {confidence:.2f}', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "        # Draw bounding boxes\n",
    "    for box in result.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        label = result.names[int(box.cls)]\n",
    "        confidence = box.conf[0]\n",
    "        cv2.rectangle(img_rgb, (x1, y1), (x2, y2), color=(255, 0, 0), thickness=2)\n",
    "        cv2.putText(img_rgb, f'{label} {confidence:.2f}', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    plt.imshow(img_rgb)\n",
    "\n",
    "    # Prepare to display masks\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img_rgb)  # Display the original image for mask overlay\n",
    "    plt.title(\"Image with Masks\")\n",
    "\n",
    "    # Overlay masks\n",
    "    for mask in result.masks.data:\n",
    "        mask = mask.cpu().numpy()\n",
    "        # Resize mask to match the image dimensions\n",
    "        mask_resized = cv2.resize(mask, (img_rgb.shape[1], img_rgb.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "        # Apply color map\n",
    "        mask_colored = cv2.applyColorMap((mask_resized * 255).astype(np.uint8), cv2.COLORMAP_SPRING)\n",
    "        # Blend the mask with the image\n",
    "        img_with_mask = cv2.addWeighted(img_rgb, 1, mask_colored, 0.6, 0)  # Adjust alpha for visibility\n",
    "\n",
    "    plt.imshow(img_with_mask)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![spoiled_fruit_test3](spoiled_fruit_test3_mask_color.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHNMgOQtDSWv"
   },
   "source": [
    "Instance Segmentation\n",
    "\n",
    "Individual Objects: Instance segmentation identifies each individual object in an image and delineates its boundaries. This means that each object of the same category is distinctly segmented with a unique identifier.\n",
    "\n",
    "Usage in YOLO: In more advanced versions of YOLO (like YOLOv3 onwards and in the YOLOv8 family), capabilities have been extended beyond bounding box predictions to include segmentation masks, which can be used for instance segmentation. This involves not only locating objects within an image but also segmenting each instance of the objects.\n",
    "\n",
    "Semantic Segmentation\n",
    "\n",
    "Category Labeling: Semantic segmentation involves dividing an image into regions based on category but does not differentiate between different instances of the same category. Every pixel is labeled with a class, but individual objects are not uniquely identified.\n",
    "\n",
    "General Approach: This type of segmentation would label all pixels of a particular class with the same color without distinguishing between different objects of the same class in the image.\n",
    "\n",
    "Given that the masks are applied per detected object in your code and include unique bounding boxes for each detected instance, it suggests the model is performing instance segmentation. This method is more detailed than semantic segmentation as it provides not only the class label but also distinguishes between different objects of the same class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSTMzqj6frUW"
   },
   "source": [
    "# Step 8. Run Prediction on test videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hcFVGvTCV_2F",
    "outputId": "128a6e05-e8b7-46be-e48e-52cf679ff2b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 fresh, 2 spoileds, 163.5ms\n",
      "Speed: 3.3ms preprocess, 163.5ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 3 spoileds, 37.6ms\n",
      "Speed: 5.8ms preprocess, 37.6ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 3 spoileds, 35.3ms\n",
      "Speed: 3.3ms preprocess, 35.3ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 38.7ms\n",
      "Speed: 5.3ms preprocess, 38.7ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 38.0ms\n",
      "Speed: 10.5ms preprocess, 38.0ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 36.4ms\n",
      "Speed: 9.4ms preprocess, 36.4ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 39.8ms\n",
      "Speed: 3.1ms preprocess, 39.8ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 36.0ms\n",
      "Speed: 3.5ms preprocess, 36.0ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 4.2ms preprocess, 33.6ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 35.3ms\n",
      "Speed: 10.5ms preprocess, 35.3ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 36.2ms\n",
      "Speed: 3.5ms preprocess, 36.2ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 37.6ms\n",
      "Speed: 3.8ms preprocess, 37.6ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.8ms\n",
      "Speed: 3.2ms preprocess, 33.8ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 33.6ms\n",
      "Speed: 3.9ms preprocess, 33.6ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 spoileds, 34.3ms\n",
      "Speed: 4.4ms preprocess, 34.3ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 spoileds, 40.9ms\n",
      "Speed: 3.2ms preprocess, 40.9ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 spoileds, 36.4ms\n",
      "Speed: 3.4ms preprocess, 36.4ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 38.6ms\n",
      "Speed: 3.4ms preprocess, 38.6ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 33.6ms\n",
      "Speed: 12.6ms preprocess, 33.6ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 2 spoileds, 33.6ms\n",
      "Speed: 3.6ms preprocess, 33.6ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 2 spoileds, 39.5ms\n",
      "Speed: 7.1ms preprocess, 39.5ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 3 spoileds, 34.1ms\n",
      "Speed: 9.5ms preprocess, 34.1ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 4 spoileds, 39.1ms\n",
      "Speed: 3.8ms preprocess, 39.1ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 spoileds, 33.9ms\n",
      "Speed: 3.3ms preprocess, 33.9ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 spoileds, 41.9ms\n",
      "Speed: 7.0ms preprocess, 41.9ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.2ms preprocess, 33.6ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 38.7ms\n",
      "Speed: 3.6ms preprocess, 38.7ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 34.2ms\n",
      "Speed: 3.3ms preprocess, 34.2ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 35.3ms\n",
      "Speed: 3.9ms preprocess, 35.3ms inference, 10.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 50.4ms\n",
      "Speed: 3.3ms preprocess, 50.4ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 33.6ms\n",
      "Speed: 3.7ms preprocess, 33.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 33.6ms\n",
      "Speed: 3.5ms preprocess, 33.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 27.6ms\n",
      "Speed: 3.7ms preprocess, 27.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 27.5ms\n",
      "Speed: 4.0ms preprocess, 27.5ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 28.1ms\n",
      "Speed: 4.6ms preprocess, 28.1ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 29.4ms\n",
      "Speed: 3.3ms preprocess, 29.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 27.5ms\n",
      "Speed: 3.6ms preprocess, 27.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.7ms\n",
      "Speed: 4.4ms preprocess, 25.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.7ms\n",
      "Speed: 3.6ms preprocess, 25.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 25.7ms\n",
      "Speed: 3.4ms preprocess, 25.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 25.7ms\n",
      "Speed: 3.2ms preprocess, 25.7ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 26.4ms\n",
      "Speed: 3.5ms preprocess, 26.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 25.7ms\n",
      "Speed: 3.5ms preprocess, 25.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 25.7ms\n",
      "Speed: 3.4ms preprocess, 25.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 25.7ms\n",
      "Speed: 3.4ms preprocess, 25.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 25.7ms\n",
      "Speed: 4.0ms preprocess, 25.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 25.3ms\n",
      "Speed: 3.4ms preprocess, 25.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.4ms\n",
      "Speed: 5.5ms preprocess, 25.4ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.3ms\n",
      "Speed: 3.4ms preprocess, 25.3ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.3ms\n",
      "Speed: 3.5ms preprocess, 25.3ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 31.2ms\n",
      "Speed: 3.4ms preprocess, 31.2ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.4ms\n",
      "Speed: 5.2ms preprocess, 25.4ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.6ms\n",
      "Speed: 3.3ms preprocess, 25.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.3ms\n",
      "Speed: 3.4ms preprocess, 25.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.2ms\n",
      "Speed: 3.8ms preprocess, 25.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 24.9ms\n",
      "Speed: 3.5ms preprocess, 24.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.0ms\n",
      "Speed: 3.9ms preprocess, 25.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 24.9ms\n",
      "Speed: 3.8ms preprocess, 24.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.0ms\n",
      "Speed: 3.6ms preprocess, 25.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 24.9ms\n",
      "Speed: 3.8ms preprocess, 24.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 25.2ms\n",
      "Speed: 3.9ms preprocess, 25.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 23.5ms\n",
      "Speed: 3.6ms preprocess, 23.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 23.3ms\n",
      "Speed: 3.8ms preprocess, 23.3ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 25.3ms\n",
      "Speed: 6.1ms preprocess, 25.3ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 30.6ms\n",
      "Speed: 6.0ms preprocess, 30.6ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 23.1ms\n",
      "Speed: 3.7ms preprocess, 23.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 23.2ms\n",
      "Speed: 3.8ms preprocess, 23.2ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 freshs, 1 spoiled, 23.1ms\n",
      "Speed: 3.4ms preprocess, 23.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 23.2ms\n",
      "Speed: 3.5ms preprocess, 23.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 freshs, 23.1ms\n",
      "Speed: 4.1ms preprocess, 23.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 2 spoileds, 23.2ms\n",
      "Speed: 4.3ms preprocess, 23.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 23.1ms\n",
      "Speed: 3.5ms preprocess, 23.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 spoileds, 23.1ms\n",
      "Speed: 3.4ms preprocess, 23.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 spoileds, 23.1ms\n",
      "Speed: 3.6ms preprocess, 23.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 23.1ms\n",
      "Speed: 3.6ms preprocess, 23.1ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 23.1ms\n",
      "Speed: 3.9ms preprocess, 23.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 23.1ms\n",
      "Speed: 3.7ms preprocess, 23.1ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 26.2ms\n",
      "Speed: 6.0ms preprocess, 26.2ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 23.2ms\n",
      "Speed: 6.4ms preprocess, 23.2ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 23.3ms\n",
      "Speed: 5.6ms preprocess, 23.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 23.2ms\n",
      "Speed: 4.3ms preprocess, 23.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 23.2ms\n",
      "Speed: 4.3ms preprocess, 23.2ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 23.1ms\n",
      "Speed: 3.9ms preprocess, 23.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 23.1ms\n",
      "Speed: 3.8ms preprocess, 23.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 23.1ms\n",
      "Speed: 3.5ms preprocess, 23.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 23.1ms\n",
      "Speed: 3.6ms preprocess, 23.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 23.1ms\n",
      "Speed: 3.7ms preprocess, 23.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 24.2ms\n",
      "Speed: 3.9ms preprocess, 24.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 24.3ms\n",
      "Speed: 3.4ms preprocess, 24.3ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 24.2ms\n",
      "Speed: 3.7ms preprocess, 24.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 24.6ms\n",
      "Speed: 3.5ms preprocess, 24.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 27.6ms\n",
      "Speed: 3.7ms preprocess, 27.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.1ms\n",
      "Speed: 5.6ms preprocess, 25.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 24.9ms\n",
      "Speed: 3.7ms preprocess, 24.9ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.0ms\n",
      "Speed: 3.4ms preprocess, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.7ms\n",
      "Speed: 3.4ms preprocess, 33.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 25.3ms\n",
      "Speed: 3.4ms preprocess, 25.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.6ms\n",
      "Speed: 3.4ms preprocess, 25.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.7ms\n",
      "Speed: 3.4ms preprocess, 25.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.7ms\n",
      "Speed: 3.7ms preprocess, 25.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.9ms\n",
      "Speed: 4.4ms preprocess, 25.9ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 25.7ms\n",
      "Speed: 4.3ms preprocess, 25.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.7ms\n",
      "Speed: 3.5ms preprocess, 25.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.3ms\n",
      "Speed: 3.7ms preprocess, 25.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.4ms\n",
      "Speed: 4.1ms preprocess, 25.4ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.3ms\n",
      "Speed: 4.4ms preprocess, 25.3ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 27.2ms\n",
      "Speed: 4.4ms preprocess, 27.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.3ms\n",
      "Speed: 6.9ms preprocess, 25.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.3ms\n",
      "Speed: 3.4ms preprocess, 25.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 25.3ms\n",
      "Speed: 3.5ms preprocess, 25.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 44.6ms\n",
      "Speed: 5.8ms preprocess, 44.6ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.5ms\n",
      "Speed: 3.5ms preprocess, 25.5ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.3ms\n",
      "Speed: 4.1ms preprocess, 25.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.3ms\n",
      "Speed: 3.7ms preprocess, 25.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.3ms\n",
      "Speed: 3.4ms preprocess, 25.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.3ms\n",
      "Speed: 3.4ms preprocess, 25.3ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 26.8ms\n",
      "Speed: 3.8ms preprocess, 26.8ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.3ms\n",
      "Speed: 3.5ms preprocess, 33.3ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 30.3ms\n",
      "Speed: 4.5ms preprocess, 30.3ms inference, 64.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.4ms\n",
      "Speed: 4.4ms preprocess, 25.4ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.3ms\n",
      "Speed: 3.3ms preprocess, 25.3ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 31.8ms\n",
      "Speed: 3.3ms preprocess, 31.8ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 28.0ms\n",
      "Speed: 3.5ms preprocess, 28.0ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 39.7ms\n",
      "Speed: 3.4ms preprocess, 39.7ms inference, 11.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 34.4ms\n",
      "Speed: 3.5ms preprocess, 34.4ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 55.7ms\n",
      "Speed: 10.0ms preprocess, 55.7ms inference, 14.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 37.8ms\n",
      "Speed: 3.5ms preprocess, 37.8ms inference, 33.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 42.3ms\n",
      "Speed: 3.4ms preprocess, 42.3ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 14.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 5.4ms preprocess, 33.6ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 45.6ms\n",
      "Speed: 3.5ms preprocess, 45.6ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.1ms preprocess, 33.6ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 34.3ms\n",
      "Speed: 4.7ms preprocess, 34.3ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 32.9ms\n",
      "Speed: 4.3ms preprocess, 32.9ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 32.8ms\n",
      "Speed: 3.1ms preprocess, 32.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 32.8ms\n",
      "Speed: 3.2ms preprocess, 32.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 26.6ms\n",
      "Speed: 3.9ms preprocess, 26.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 26.6ms\n",
      "Speed: 3.4ms preprocess, 26.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 26.5ms\n",
      "Speed: 3.4ms preprocess, 26.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.7ms\n",
      "Speed: 3.1ms preprocess, 25.7ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.7ms\n",
      "Speed: 3.1ms preprocess, 25.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.7ms\n",
      "Speed: 3.4ms preprocess, 25.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.7ms\n",
      "Speed: 4.5ms preprocess, 25.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.7ms\n",
      "Speed: 3.2ms preprocess, 25.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.7ms\n",
      "Speed: 3.8ms preprocess, 25.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.3ms\n",
      "Speed: 3.8ms preprocess, 25.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.4ms\n",
      "Speed: 3.6ms preprocess, 25.4ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.3ms\n",
      "Speed: 3.0ms preprocess, 25.3ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 28.0ms\n",
      "Speed: 4.8ms preprocess, 28.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.3ms\n",
      "Speed: 5.7ms preprocess, 25.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.3ms\n",
      "Speed: 3.0ms preprocess, 25.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.3ms\n",
      "Speed: 3.6ms preprocess, 25.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.3ms\n",
      "Speed: 3.4ms preprocess, 25.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.3ms\n",
      "Speed: 3.0ms preprocess, 25.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 23.6ms\n",
      "Speed: 4.2ms preprocess, 23.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 26.3ms\n",
      "Speed: 4.3ms preprocess, 26.3ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 26.6ms\n",
      "Speed: 5.5ms preprocess, 26.6ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 27.5ms\n",
      "Speed: 3.5ms preprocess, 27.5ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 31.6ms\n",
      "Speed: 3.9ms preprocess, 31.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 31.1ms\n",
      "Speed: 3.8ms preprocess, 31.1ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 23.6ms\n",
      "Speed: 3.3ms preprocess, 23.6ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.4ms\n",
      "Speed: 5.4ms preprocess, 33.4ms inference, 9.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 29.1ms\n",
      "Speed: 4.2ms preprocess, 29.1ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 23.6ms\n",
      "Speed: 3.3ms preprocess, 23.6ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 23.6ms\n",
      "Speed: 5.2ms preprocess, 23.6ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.6ms\n",
      "Speed: 3.9ms preprocess, 25.6ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 30.9ms\n",
      "Speed: 3.0ms preprocess, 30.9ms inference, 15.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 23.7ms\n",
      "Speed: 3.4ms preprocess, 23.7ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 27.2ms\n",
      "Speed: 3.4ms preprocess, 27.2ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 23.6ms\n",
      "Speed: 3.2ms preprocess, 23.6ms inference, 10.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 28.4ms\n",
      "Speed: 3.4ms preprocess, 28.4ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.0ms\n",
      "Speed: 9.0ms preprocess, 33.0ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 37.0ms\n",
      "Speed: 8.0ms preprocess, 37.0ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 24.2ms\n",
      "Speed: 5.7ms preprocess, 24.2ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 27.0ms\n",
      "Speed: 3.3ms preprocess, 27.0ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 32.6ms\n",
      "Speed: 4.8ms preprocess, 32.6ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 29.8ms\n",
      "Speed: 5.3ms preprocess, 29.8ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 32.3ms\n",
      "Speed: 3.4ms preprocess, 32.3ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 27.4ms\n",
      "Speed: 4.1ms preprocess, 27.4ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 30.2ms\n",
      "Speed: 3.9ms preprocess, 30.2ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 27.5ms\n",
      "Speed: 3.3ms preprocess, 27.5ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.7ms\n",
      "Speed: 4.1ms preprocess, 33.7ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 36.4ms\n",
      "Speed: 10.5ms preprocess, 36.4ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 29.0ms\n",
      "Speed: 5.6ms preprocess, 29.0ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 30.1ms\n",
      "Speed: 4.0ms preprocess, 30.1ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 29.6ms\n",
      "Speed: 7.8ms preprocess, 29.6ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 34.0ms\n",
      "Speed: 3.9ms preprocess, 34.0ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 36.8ms\n",
      "Speed: 8.3ms preprocess, 36.8ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 32.7ms\n",
      "Speed: 3.5ms preprocess, 32.7ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 42.4ms\n",
      "Speed: 3.4ms preprocess, 42.4ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 30.2ms\n",
      "Speed: 3.3ms preprocess, 30.2ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.0ms\n",
      "Speed: 3.4ms preprocess, 33.0ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 40.7ms\n",
      "Speed: 7.0ms preprocess, 40.7ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 31.4ms\n",
      "Speed: 3.5ms preprocess, 31.4ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 31.5ms\n",
      "Speed: 3.2ms preprocess, 31.5ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 31.0ms\n",
      "Speed: 3.3ms preprocess, 31.0ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 34.9ms\n",
      "Speed: 3.6ms preprocess, 34.9ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 36.2ms\n",
      "Speed: 5.7ms preprocess, 36.2ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 31.2ms\n",
      "Speed: 3.4ms preprocess, 31.2ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 31.7ms\n",
      "Speed: 8.5ms preprocess, 31.7ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 30.6ms\n",
      "Speed: 6.7ms preprocess, 30.6ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 34.0ms\n",
      "Speed: 10.6ms preprocess, 34.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 38.9ms\n",
      "Speed: 9.6ms preprocess, 38.9ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 32.5ms\n",
      "Speed: 3.4ms preprocess, 32.5ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 33.3ms\n",
      "Speed: 6.0ms preprocess, 33.3ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 35.2ms\n",
      "Speed: 3.5ms preprocess, 35.2ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 30.2ms\n",
      "Speed: 3.5ms preprocess, 30.2ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 30.2ms\n",
      "Speed: 3.4ms preprocess, 30.2ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 spoileds, 35.7ms\n",
      "Speed: 5.8ms preprocess, 35.7ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 33.9ms\n",
      "Speed: 3.3ms preprocess, 33.9ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 spoileds, 32.1ms\n",
      "Speed: 3.5ms preprocess, 32.1ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 34.4ms\n",
      "Speed: 6.6ms preprocess, 34.4ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 36.3ms\n",
      "Speed: 3.2ms preprocess, 36.3ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 35.6ms\n",
      "Speed: 5.3ms preprocess, 35.6ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 35.4ms\n",
      "Speed: 4.0ms preprocess, 35.4ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 38.3ms\n",
      "Speed: 7.5ms preprocess, 38.3ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 38.0ms\n",
      "Speed: 3.3ms preprocess, 38.0ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 9.8ms preprocess, 33.6ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 36.7ms\n",
      "Speed: 3.5ms preprocess, 36.7ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 35.6ms\n",
      "Speed: 5.5ms preprocess, 35.6ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 34.2ms\n",
      "Speed: 3.4ms preprocess, 34.2ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 42.8ms\n",
      "Speed: 5.4ms preprocess, 42.8ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 42.0ms\n",
      "Speed: 6.5ms preprocess, 42.0ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 40.4ms\n",
      "Speed: 8.1ms preprocess, 40.4ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.5ms preprocess, 33.6ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.1ms\n",
      "Speed: 6.6ms preprocess, 35.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.7ms\n",
      "Speed: 6.6ms preprocess, 37.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 36.4ms\n",
      "Speed: 4.1ms preprocess, 36.4ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.8ms\n",
      "Speed: 3.6ms preprocess, 33.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.6ms\n",
      "Speed: 10.6ms preprocess, 33.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.5ms\n",
      "Speed: 3.4ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 34.9ms\n",
      "Speed: 3.4ms preprocess, 34.9ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.9ms\n",
      "Speed: 7.9ms preprocess, 40.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.1ms\n",
      "Speed: 12.0ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.3ms\n",
      "Speed: 3.8ms preprocess, 36.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.6ms\n",
      "Speed: 3.9ms preprocess, 35.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 33.6ms\n",
      "Speed: 3.5ms preprocess, 33.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 33.6ms\n",
      "Speed: 3.1ms preprocess, 33.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 27.0ms\n",
      "Speed: 4.8ms preprocess, 27.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 27.0ms\n",
      "Speed: 3.5ms preprocess, 27.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 27.1ms\n",
      "Speed: 3.6ms preprocess, 27.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 26.2ms\n",
      "Speed: 3.5ms preprocess, 26.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 26.1ms\n",
      "Speed: 3.7ms preprocess, 26.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 26.1ms\n",
      "Speed: 4.0ms preprocess, 26.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 26.2ms\n",
      "Speed: 3.7ms preprocess, 26.2ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 27.9ms\n",
      "Speed: 6.3ms preprocess, 27.9ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 26.5ms\n",
      "Speed: 3.6ms preprocess, 26.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 26.1ms\n",
      "Speed: 4.0ms preprocess, 26.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 26.1ms\n",
      "Speed: 4.4ms preprocess, 26.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 25.7ms\n",
      "Speed: 3.1ms preprocess, 25.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 25.7ms\n",
      "Speed: 3.6ms preprocess, 25.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 25.7ms\n",
      "Speed: 3.3ms preprocess, 25.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 25.7ms\n",
      "Speed: 4.1ms preprocess, 25.7ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 25.8ms\n",
      "Speed: 3.3ms preprocess, 25.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 25.7ms\n",
      "Speed: 3.7ms preprocess, 25.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 25.7ms\n",
      "Speed: 3.8ms preprocess, 25.7ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 25.8ms\n",
      "Speed: 3.8ms preprocess, 25.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 25.7ms\n",
      "Speed: 4.9ms preprocess, 25.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 25.7ms\n",
      "Speed: 3.4ms preprocess, 25.7ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 25.7ms\n",
      "Speed: 3.4ms preprocess, 25.7ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 26.7ms\n",
      "Speed: 3.6ms preprocess, 26.7ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 27.8ms\n",
      "Speed: 5.1ms preprocess, 27.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 25.7ms\n",
      "Speed: 3.5ms preprocess, 25.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 25.7ms\n",
      "Speed: 3.7ms preprocess, 25.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 25.7ms\n",
      "Speed: 4.0ms preprocess, 25.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 25.7ms\n",
      "Speed: 4.5ms preprocess, 25.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 25.4ms\n",
      "Speed: 3.8ms preprocess, 25.4ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 24.6ms\n",
      "Speed: 4.0ms preprocess, 24.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 24.6ms\n",
      "Speed: 3.8ms preprocess, 24.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 24.6ms\n",
      "Speed: 4.1ms preprocess, 24.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 24.6ms\n",
      "Speed: 3.4ms preprocess, 24.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 25.6ms\n",
      "Speed: 3.5ms preprocess, 25.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 24.5ms\n",
      "Speed: 3.3ms preprocess, 24.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 25.0ms\n",
      "Speed: 3.3ms preprocess, 25.0ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 25.0ms\n",
      "Speed: 3.6ms preprocess, 25.0ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 29.1ms\n",
      "Speed: 4.2ms preprocess, 29.1ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 24.7ms\n",
      "Speed: 4.3ms preprocess, 24.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 24.6ms\n",
      "Speed: 3.3ms preprocess, 24.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 24.6ms\n",
      "Speed: 4.1ms preprocess, 24.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 24.6ms\n",
      "Speed: 3.4ms preprocess, 24.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 24.6ms\n",
      "Speed: 5.6ms preprocess, 24.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 24.6ms\n",
      "Speed: 3.4ms preprocess, 24.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 24.6ms\n",
      "Speed: 4.0ms preprocess, 24.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 24.6ms\n",
      "Speed: 3.4ms preprocess, 24.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 3 spoileds, 24.6ms\n",
      "Speed: 4.0ms preprocess, 24.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 3 spoileds, 24.6ms\n",
      "Speed: 4.1ms preprocess, 24.6ms inference, 9.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 2 spoileds, 24.6ms\n",
      "Speed: 4.2ms preprocess, 24.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 2 spoileds, 24.6ms\n",
      "Speed: 4.0ms preprocess, 24.6ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 25.5ms\n",
      "Speed: 6.3ms preprocess, 25.5ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 25.0ms\n",
      "Speed: 8.4ms preprocess, 25.0ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 27.7ms\n",
      "Speed: 8.9ms preprocess, 27.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 24.6ms\n",
      "Speed: 3.3ms preprocess, 24.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 3.5ms preprocess, 25.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 3.4ms preprocess, 25.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.5ms preprocess, 25.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.4ms\n",
      "Speed: 3.7ms preprocess, 25.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.3ms\n",
      "Speed: 3.6ms preprocess, 25.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 26.5ms\n",
      "Speed: 3.4ms preprocess, 26.5ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.3ms\n",
      "Speed: 3.4ms preprocess, 25.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.3ms\n",
      "Speed: 5.5ms preprocess, 25.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.3ms\n",
      "Speed: 3.5ms preprocess, 25.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 2 spoileds, 25.3ms\n",
      "Speed: 6.6ms preprocess, 25.3ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 26.9ms\n",
      "Speed: 9.2ms preprocess, 26.9ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 freshs, 2 spoileds, 25.4ms\n",
      "Speed: 3.5ms preprocess, 25.4ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 2 spoileds, 25.4ms\n",
      "Speed: 4.4ms preprocess, 25.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 25.3ms\n",
      "Speed: 6.0ms preprocess, 25.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 25.3ms\n",
      "Speed: 3.4ms preprocess, 25.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 25.3ms\n",
      "Speed: 3.7ms preprocess, 25.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.3ms\n",
      "Speed: 3.8ms preprocess, 25.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 24.8ms\n",
      "Speed: 4.2ms preprocess, 24.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 24.6ms\n",
      "Speed: 4.0ms preprocess, 24.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 24.6ms\n",
      "Speed: 3.4ms preprocess, 24.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 24.6ms\n",
      "Speed: 3.4ms preprocess, 24.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 24.6ms\n",
      "Speed: 3.9ms preprocess, 24.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 26.7ms\n",
      "Speed: 4.1ms preprocess, 26.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 24.7ms\n",
      "Speed: 3.5ms preprocess, 24.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 24.6ms\n",
      "Speed: 3.3ms preprocess, 24.6ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 26.2ms\n",
      "Speed: 4.7ms preprocess, 26.2ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 26.6ms\n",
      "Speed: 3.3ms preprocess, 26.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 24.6ms\n",
      "Speed: 3.2ms preprocess, 24.6ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 24.6ms\n",
      "Speed: 3.3ms preprocess, 24.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.2ms\n",
      "Speed: 3.8ms preprocess, 25.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 24.6ms\n",
      "Speed: 3.3ms preprocess, 24.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 24.6ms\n",
      "Speed: 3.4ms preprocess, 24.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 24.6ms\n",
      "Speed: 3.7ms preprocess, 24.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 24.6ms\n",
      "Speed: 4.2ms preprocess, 24.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 24.6ms\n",
      "Speed: 3.4ms preprocess, 24.6ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 24.6ms\n",
      "Speed: 3.2ms preprocess, 24.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.9ms\n",
      "Speed: 3.4ms preprocess, 25.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 24.6ms\n",
      "Speed: 3.5ms preprocess, 24.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 24.6ms\n",
      "Speed: 5.6ms preprocess, 24.6ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 27.8ms\n",
      "Speed: 3.4ms preprocess, 27.8ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 27.4ms\n",
      "Speed: 3.2ms preprocess, 27.4ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 27.3ms\n",
      "Speed: 4.9ms preprocess, 27.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 24.6ms\n",
      "Speed: 3.7ms preprocess, 24.6ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.7ms\n",
      "Speed: 7.4ms preprocess, 25.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.7ms\n",
      "Speed: 3.4ms preprocess, 25.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.7ms\n",
      "Speed: 3.4ms preprocess, 25.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.7ms\n",
      "Speed: 3.5ms preprocess, 25.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.7ms\n",
      "Speed: 3.2ms preprocess, 25.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.7ms\n",
      "Speed: 3.4ms preprocess, 25.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.7ms\n",
      "Speed: 3.4ms preprocess, 25.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.7ms\n",
      "Speed: 3.7ms preprocess, 25.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.8ms\n",
      "Speed: 3.4ms preprocess, 25.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.8ms\n",
      "Speed: 3.2ms preprocess, 25.8ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.7ms\n",
      "Speed: 3.3ms preprocess, 25.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 27.4ms\n",
      "Speed: 5.4ms preprocess, 27.4ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 27.0ms\n",
      "Speed: 3.7ms preprocess, 27.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 26.1ms\n",
      "Speed: 4.1ms preprocess, 26.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.7ms\n",
      "Speed: 3.4ms preprocess, 25.7ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.7ms\n",
      "Speed: 3.4ms preprocess, 25.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.7ms\n",
      "Speed: 7.3ms preprocess, 25.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.7ms\n",
      "Speed: 3.4ms preprocess, 25.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 25.7ms\n",
      "Speed: 3.4ms preprocess, 25.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 25.7ms\n",
      "Speed: 3.1ms preprocess, 25.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Initialize the video capture and the YOLO model\n",
    "video_path = \"/content/drive/My Drive/Colab Notebooks/spoiled_fruit_input_test_video.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Video writer to save output\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('/content/output_video.mp4', fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "model = YOLO(\"/content/datasets/runs/segment/train/weights/best.pt\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Predict using YOLO\n",
    "    results = model.predict(source=frame, conf=0.25)\n",
    "\n",
    "    # Process each result\n",
    "    for result in results:\n",
    "        if hasattr(result, 'boxes'):\n",
    "            boxes = result.boxes.cpu().numpy()  # Move boxes to CPU and convert to numpy array\n",
    "            for box in boxes:\n",
    "                r = box.xyxy[0].astype(int)  # Rectangle coordinates\n",
    "                class_id = int(box.cls[0])  # Class ID\n",
    "                class_name = model.names[class_id]  # Get class name using the class ID\n",
    "\n",
    "                # Draw bounding box and label on the frame\n",
    "                cv2.rectangle(frame, (r[0], r[1]), (r[2], r[3]), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"{class_name} {box.conf[0]:.2f}\", (r[0], r[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # Write the processed frame to the output video\n",
    "    out.write(frame)\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4WvMM4gfWhbY",
    "outputId": "6b6632c2-65fb-4b56-d59e-2547fdd22942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'output_video.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:00:12.35, start: 0.000000, bitrate: 23899 kb/s\n",
      "  Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], 23898 kb/s, 29 fps, 29 tbr, 14848 tbn, 29 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x5bf2315f6e00] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x5bf2315f6e00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
      "\u001b[1;36m[libx264 @ 0x5bf2315f6e00] \u001b[0mprofile High, level 4.0, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x5bf2315f6e00] \u001b[0m264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'output_video_conv.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 1920x1080 [SAR 1:1 DAR 16:9], q=2-31, 29 fps, 14848 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  358 fps=5.6 q=-1.0 Lsize=   12998kB time=00:00:12.24 bitrate=8698.2kbits/s speed=0.191x    \n",
      "video:12995kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.025176%\n",
      "\u001b[1;36m[libx264 @ 0x5bf2315f6e00] \u001b[0mframe I:2     Avg QP:22.81  size:241631\n",
      "\u001b[1;36m[libx264 @ 0x5bf2315f6e00] \u001b[0mframe P:303   Avg QP:24.41  size: 40297\n",
      "\u001b[1;36m[libx264 @ 0x5bf2315f6e00] \u001b[0mframe B:53    Avg QP:28.94  size: 11557\n",
      "\u001b[1;36m[libx264 @ 0x5bf2315f6e00] \u001b[0mconsecutive B-frames: 76.5%  8.9%  6.7%  7.8%\n",
      "\u001b[1;36m[libx264 @ 0x5bf2315f6e00] \u001b[0mmb I  I16..4:  1.6% 92.7%  5.7%\n",
      "\u001b[1;36m[libx264 @ 0x5bf2315f6e00] \u001b[0mmb P  I16..4:  2.7%  8.7%  0.6%  P16..4: 46.0% 14.3%  9.8%  0.0%  0.0%    skip:18.0%\n",
      "\u001b[1;36m[libx264 @ 0x5bf2315f6e00] \u001b[0mmb B  I16..4:  1.7%  3.9%  0.2%  B16..8: 36.9%  2.3%  0.6%  direct: 1.6%  skip:52.8%  L0:44.2% L1:46.5% BI: 9.3%\n",
      "\u001b[1;36m[libx264 @ 0x5bf2315f6e00] \u001b[0m8x8 transform intra:73.2% inter:75.8%\n",
      "\u001b[1;36m[libx264 @ 0x5bf2315f6e00] \u001b[0mcoded y,uvDC,uvAC intra: 54.3% 65.9% 11.2% inter: 30.8% 25.1% 1.4%\n",
      "\u001b[1;36m[libx264 @ 0x5bf2315f6e00] \u001b[0mi16 v,h,dc,p: 35% 28% 16% 21%\n",
      "\u001b[1;36m[libx264 @ 0x5bf2315f6e00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 25% 23% 29%  4%  4%  3%  4%  3%  5%\n",
      "\u001b[1;36m[libx264 @ 0x5bf2315f6e00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 28% 22% 10%  5%  8%  6%  8%  5%  6%\n",
      "\u001b[1;36m[libx264 @ 0x5bf2315f6e00] \u001b[0mi8c dc,h,v,p: 43% 27% 26%  4%\n",
      "\u001b[1;36m[libx264 @ 0x5bf2315f6e00] \u001b[0mWeighted P-Frames: Y:5.9% UV:1.0%\n",
      "\u001b[1;36m[libx264 @ 0x5bf2315f6e00] \u001b[0mref P L0: 71.8% 23.0%  4.1%  1.0%  0.0%\n",
      "\u001b[1;36m[libx264 @ 0x5bf2315f6e00] \u001b[0mref B L0: 96.1%  3.4%  0.5%\n",
      "\u001b[1;36m[libx264 @ 0x5bf2315f6e00] \u001b[0mref B L1: 99.7%  0.3%\n",
      "\u001b[1;36m[libx264 @ 0x5bf2315f6e00] \u001b[0mkb/s:8622.78\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -i output_video.mp4 -vcodec libx264 -y output_video_conv.mp4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RuJffo1Dfyz-"
   },
   "source": [
    "# Step 10. Display Inference Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "C3om0I2lXzcC",
    "outputId": "e59600f5-c99a-474c-c40a-655aea86d06f"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "# Function to display the processed video\n",
    "def display_video(video_path):\n",
    "    mp4 = open(video_path,'rb').read()\n",
    "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "    return HTML(\"\"\"\n",
    "        <video width=700 controls>\n",
    "            <source src=\"%s\" type=\"video/mp4\">\n",
    "        </video>\n",
    "    \"\"\" % data_url)\n",
    "\n",
    "# Display the processed video\n",
    "display_video(\"output_video_conv.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![spoil_video_out_1](spoil_video_out_1.png)\n",
    "\n",
    "![spoil_video_out_2](spoil_video_out_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "eG1s5YobWhi1",
    "outputId": "fecc80f7-8505-4b25-d0c6-e91579edfc01"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_214d0a83-a948-4879-8c71-9483fe085bba\", \"output_video.mp4\", 36880027)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "output_path='/content/output_video.mp4'\n",
    "# Download the processed video file\n",
    "files.download(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n7V3hRH5MotC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gyYIcZZtMowX"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VJV0FVJf9eS"
   },
   "source": [
    "# Step 11. Display Inference Video with masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-bt1yW23c5av",
    "outputId": "2285487c-1259-426f-987c-393565bca807"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 fresh, 2 spoileds, 34.8ms\n",
      "Speed: 2.9ms preprocess, 34.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 3 spoileds, 30.4ms\n",
      "Speed: 3.8ms preprocess, 30.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 3 spoileds, 30.2ms\n",
      "Speed: 3.6ms preprocess, 30.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 30.2ms\n",
      "Speed: 6.1ms preprocess, 30.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 30.2ms\n",
      "Speed: 3.6ms preprocess, 30.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 30.2ms\n",
      "Speed: 3.5ms preprocess, 30.2ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 30.2ms\n",
      "Speed: 3.4ms preprocess, 30.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 30.2ms\n",
      "Speed: 3.4ms preprocess, 30.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 30.2ms\n",
      "Speed: 5.2ms preprocess, 30.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 30.2ms\n",
      "Speed: 3.1ms preprocess, 30.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 30.1ms\n",
      "Speed: 3.3ms preprocess, 30.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 30.3ms\n",
      "Speed: 3.6ms preprocess, 30.3ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 30.8ms\n",
      "Speed: 3.3ms preprocess, 30.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 30.2ms\n",
      "Speed: 3.8ms preprocess, 30.2ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 spoileds, 30.1ms\n",
      "Speed: 3.9ms preprocess, 30.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 spoileds, 30.2ms\n",
      "Speed: 6.6ms preprocess, 30.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 spoileds, 30.2ms\n",
      "Speed: 3.7ms preprocess, 30.2ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 31.8ms\n",
      "Speed: 4.0ms preprocess, 31.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 33.5ms\n",
      "Speed: 3.6ms preprocess, 33.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 2 spoileds, 33.6ms\n",
      "Speed: 4.2ms preprocess, 33.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 2 spoileds, 33.6ms\n",
      "Speed: 3.6ms preprocess, 33.6ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 3 spoileds, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 4 spoileds, 33.6ms\n",
      "Speed: 4.5ms preprocess, 33.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 spoileds, 33.6ms\n",
      "Speed: 4.0ms preprocess, 33.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 spoileds, 33.6ms\n",
      "Speed: 3.8ms preprocess, 33.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 4.3ms preprocess, 33.6ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.3ms preprocess, 33.6ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 4.1ms preprocess, 33.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 32.8ms\n",
      "Speed: 3.4ms preprocess, 32.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 32.8ms\n",
      "Speed: 4.9ms preprocess, 32.8ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 32.8ms\n",
      "Speed: 4.1ms preprocess, 32.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 37.6ms\n",
      "Speed: 6.2ms preprocess, 37.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 32.8ms\n",
      "Speed: 3.4ms preprocess, 32.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 32.8ms\n",
      "Speed: 3.9ms preprocess, 32.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 32.8ms\n",
      "Speed: 3.8ms preprocess, 32.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 32.8ms\n",
      "Speed: 4.4ms preprocess, 32.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 32.8ms\n",
      "Speed: 4.4ms preprocess, 32.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 32.9ms\n",
      "Speed: 3.7ms preprocess, 32.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 32.8ms\n",
      "Speed: 4.2ms preprocess, 32.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 32.8ms\n",
      "Speed: 3.9ms preprocess, 32.8ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 32.9ms\n",
      "Speed: 5.9ms preprocess, 32.9ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 32.8ms\n",
      "Speed: 3.6ms preprocess, 32.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 32.8ms\n",
      "Speed: 5.5ms preprocess, 32.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 32.8ms\n",
      "Speed: 3.3ms preprocess, 32.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 32.8ms\n",
      "Speed: 3.8ms preprocess, 32.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 32.8ms\n",
      "Speed: 3.5ms preprocess, 32.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 33.6ms\n",
      "Speed: 4.0ms preprocess, 33.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 33.6ms\n",
      "Speed: 5.7ms preprocess, 33.6ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.9ms\n",
      "Speed: 3.4ms preprocess, 33.9ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 6.2ms preprocess, 33.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.1ms preprocess, 33.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.3ms preprocess, 33.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.8ms\n",
      "Speed: 7.0ms preprocess, 33.8ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.6ms\n",
      "Speed: 3.6ms preprocess, 33.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.2ms preprocess, 33.6ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 7.3ms preprocess, 33.6ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 35.1ms\n",
      "Speed: 3.4ms preprocess, 35.1ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 39.3ms\n",
      "Speed: 9.8ms preprocess, 39.3ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 35.7ms\n",
      "Speed: 3.4ms preprocess, 35.7ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 33.6ms\n",
      "Speed: 3.8ms preprocess, 33.6ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 61.8ms\n",
      "Speed: 11.1ms preprocess, 61.8ms inference, 12.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 34.4ms\n",
      "Speed: 3.6ms preprocess, 34.4ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 39.5ms\n",
      "Speed: 3.8ms preprocess, 39.5ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 37.1ms\n",
      "Speed: 12.5ms preprocess, 37.1ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 40.6ms\n",
      "Speed: 3.4ms preprocess, 40.6ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.6ms preprocess, 33.6ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 freshs, 1 spoiled, 33.6ms\n",
      "Speed: 4.1ms preprocess, 33.6ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 33.6ms\n",
      "Speed: 5.5ms preprocess, 33.6ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 freshs, 33.9ms\n",
      "Speed: 4.0ms preprocess, 33.9ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 2 spoileds, 33.6ms\n",
      "Speed: 10.5ms preprocess, 33.6ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.7ms\n",
      "Speed: 7.2ms preprocess, 33.7ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 spoileds, 40.1ms\n",
      "Speed: 6.6ms preprocess, 40.1ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 spoileds, 35.5ms\n",
      "Speed: 3.4ms preprocess, 35.5ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 39.3ms\n",
      "Speed: 4.7ms preprocess, 39.3ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 35.5ms\n",
      "Speed: 3.3ms preprocess, 35.5ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 33.6ms\n",
      "Speed: 3.7ms preprocess, 33.6ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 35.1ms\n",
      "Speed: 3.8ms preprocess, 35.1ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.5ms\n",
      "Speed: 3.4ms preprocess, 33.5ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 38.4ms\n",
      "Speed: 4.2ms preprocess, 38.4ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 35.3ms\n",
      "Speed: 5.7ms preprocess, 35.3ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 34.4ms\n",
      "Speed: 3.3ms preprocess, 34.4ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.8ms preprocess, 33.6ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 40.6ms\n",
      "Speed: 5.4ms preprocess, 40.6ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 37.8ms\n",
      "Speed: 6.1ms preprocess, 37.8ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 34.0ms\n",
      "Speed: 5.7ms preprocess, 34.0ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.9ms preprocess, 33.6ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 36.0ms\n",
      "Speed: 7.1ms preprocess, 36.0ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.2ms preprocess, 33.6ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 40.8ms\n",
      "Speed: 3.3ms preprocess, 40.8ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.7ms\n",
      "Speed: 3.3ms preprocess, 33.7ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 39.7ms\n",
      "Speed: 3.3ms preprocess, 39.7ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.8ms preprocess, 33.6ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 7.2ms preprocess, 33.6ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.7ms preprocess, 33.6ms inference, 9.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 36.3ms\n",
      "Speed: 5.3ms preprocess, 36.3ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 33.6ms\n",
      "Speed: 3.2ms preprocess, 33.6ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 37.0ms\n",
      "Speed: 3.6ms preprocess, 37.0ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.5ms preprocess, 33.6ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 41.5ms\n",
      "Speed: 3.4ms preprocess, 41.5ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 35.5ms\n",
      "Speed: 3.5ms preprocess, 35.5ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 38.6ms\n",
      "Speed: 3.6ms preprocess, 38.6ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 39.8ms\n",
      "Speed: 3.2ms preprocess, 39.8ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 38.8ms\n",
      "Speed: 3.2ms preprocess, 38.8ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 38.8ms\n",
      "Speed: 3.3ms preprocess, 38.8ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 45.0ms\n",
      "Speed: 3.3ms preprocess, 45.0ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 34.2ms\n",
      "Speed: 5.0ms preprocess, 34.2ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 42.9ms\n",
      "Speed: 5.1ms preprocess, 42.9ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 4.2ms preprocess, 33.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 33.6ms\n",
      "Speed: 3.2ms preprocess, 33.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.8ms preprocess, 33.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 34.8ms\n",
      "Speed: 3.4ms preprocess, 34.8ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 4.6ms preprocess, 33.6ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.8ms preprocess, 33.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.8ms preprocess, 33.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.5ms\n",
      "Speed: 3.4ms preprocess, 33.5ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.9ms preprocess, 33.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.5ms preprocess, 33.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.5ms\n",
      "Speed: 3.6ms preprocess, 33.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 36.6ms\n",
      "Speed: 4.5ms preprocess, 36.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.5ms preprocess, 33.6ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.2ms preprocess, 33.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.3ms preprocess, 33.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.8ms preprocess, 33.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.5ms\n",
      "Speed: 3.1ms preprocess, 33.5ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.9ms preprocess, 33.6ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 5.8ms preprocess, 33.6ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 4.2ms preprocess, 33.6ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 5.1ms preprocess, 33.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.3ms preprocess, 33.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 4.4ms preprocess, 33.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.2ms preprocess, 33.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 4.9ms preprocess, 33.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 4.3ms preprocess, 33.6ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.7ms preprocess, 33.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 4.6ms preprocess, 33.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.5ms preprocess, 33.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.9ms preprocess, 33.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 34.3ms\n",
      "Speed: 3.2ms preprocess, 34.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.5ms preprocess, 33.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.3ms preprocess, 33.6ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 4.0ms preprocess, 33.6ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 4.1ms preprocess, 33.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.7ms preprocess, 33.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 34.2ms\n",
      "Speed: 3.4ms preprocess, 34.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 6.9ms preprocess, 33.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 4.4ms preprocess, 33.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.5ms preprocess, 33.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.7ms\n",
      "Speed: 3.8ms preprocess, 33.7ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 4.1ms preprocess, 33.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.5ms preprocess, 33.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.5ms preprocess, 33.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.3ms preprocess, 33.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.5ms\n",
      "Speed: 3.7ms preprocess, 33.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.9ms preprocess, 33.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 4.0ms preprocess, 33.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.3ms preprocess, 33.6ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 7.7ms preprocess, 33.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.5ms\n",
      "Speed: 3.4ms preprocess, 33.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 5.1ms preprocess, 33.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.6ms preprocess, 33.6ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.9ms preprocess, 33.6ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 4.2ms preprocess, 33.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.3ms preprocess, 33.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 5.5ms preprocess, 33.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.8ms preprocess, 33.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.7ms\n",
      "Speed: 4.1ms preprocess, 33.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 4.0ms preprocess, 33.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 7.3ms preprocess, 33.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 32.8ms\n",
      "Speed: 4.0ms preprocess, 32.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 30.2ms\n",
      "Speed: 3.4ms preprocess, 30.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 30.2ms\n",
      "Speed: 3.5ms preprocess, 30.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 30.2ms\n",
      "Speed: 3.8ms preprocess, 30.2ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 32.3ms\n",
      "Speed: 3.5ms preprocess, 32.3ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 30.2ms\n",
      "Speed: 3.4ms preprocess, 30.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 30.2ms\n",
      "Speed: 3.2ms preprocess, 30.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 30.2ms\n",
      "Speed: 3.6ms preprocess, 30.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 30.2ms\n",
      "Speed: 3.4ms preprocess, 30.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 30.2ms\n",
      "Speed: 3.5ms preprocess, 30.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 30.2ms\n",
      "Speed: 3.4ms preprocess, 30.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 30.2ms\n",
      "Speed: 3.2ms preprocess, 30.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 31.0ms\n",
      "Speed: 3.6ms preprocess, 31.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 30.2ms\n",
      "Speed: 3.4ms preprocess, 30.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 30.3ms\n",
      "Speed: 5.1ms preprocess, 30.3ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 34.6ms\n",
      "Speed: 3.4ms preprocess, 34.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 30.2ms\n",
      "Speed: 3.5ms preprocess, 30.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 30.2ms\n",
      "Speed: 3.8ms preprocess, 30.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 30.4ms\n",
      "Speed: 3.2ms preprocess, 30.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 36.3ms\n",
      "Speed: 6.3ms preprocess, 36.3ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 32.9ms\n",
      "Speed: 9.1ms preprocess, 32.9ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 39.6ms\n",
      "Speed: 5.2ms preprocess, 39.6ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 33.6ms\n",
      "Speed: 3.2ms preprocess, 33.6ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 spoileds, 34.6ms\n",
      "Speed: 3.3ms preprocess, 34.6ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 33.6ms\n",
      "Speed: 3.5ms preprocess, 33.6ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 spoileds, 35.8ms\n",
      "Speed: 3.4ms preprocess, 35.8ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 8.2ms preprocess, 33.6ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 34.9ms\n",
      "Speed: 3.3ms preprocess, 34.9ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 35.9ms\n",
      "Speed: 3.6ms preprocess, 35.9ms inference, 9.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 39.7ms\n",
      "Speed: 3.4ms preprocess, 39.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 36.3ms\n",
      "Speed: 3.6ms preprocess, 36.3ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 34.4ms\n",
      "Speed: 3.3ms preprocess, 34.4ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 35.4ms\n",
      "Speed: 3.3ms preprocess, 35.4ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 35.3ms\n",
      "Speed: 3.6ms preprocess, 35.3ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 45.1ms\n",
      "Speed: 3.4ms preprocess, 45.1ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 36.1ms\n",
      "Speed: 3.4ms preprocess, 36.1ms inference, 9.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 40.9ms\n",
      "Speed: 3.4ms preprocess, 40.9ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 36.4ms\n",
      "Speed: 3.4ms preprocess, 36.4ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 38.8ms\n",
      "Speed: 3.4ms preprocess, 38.8ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.9ms\n",
      "Speed: 3.7ms preprocess, 37.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.6ms\n",
      "Speed: 5.7ms preprocess, 33.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 35.6ms\n",
      "Speed: 3.3ms preprocess, 35.6ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.1ms\n",
      "Speed: 3.7ms preprocess, 37.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.8ms\n",
      "Speed: 3.5ms preprocess, 41.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 40.2ms\n",
      "Speed: 6.9ms preprocess, 40.2ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.3ms\n",
      "Speed: 5.5ms preprocess, 34.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.6ms\n",
      "Speed: 3.5ms preprocess, 33.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.6ms\n",
      "Speed: 7.7ms preprocess, 33.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.6ms\n",
      "Speed: 3.4ms preprocess, 33.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 45.1ms\n",
      "Speed: 7.5ms preprocess, 45.1ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 34.8ms\n",
      "Speed: 3.6ms preprocess, 34.8ms inference, 9.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 37.8ms\n",
      "Speed: 5.4ms preprocess, 37.8ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 38.2ms\n",
      "Speed: 7.4ms preprocess, 38.2ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 33.6ms\n",
      "Speed: 4.0ms preprocess, 33.6ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 38.5ms\n",
      "Speed: 3.5ms preprocess, 38.5ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 39.6ms\n",
      "Speed: 4.2ms preprocess, 39.6ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 34.7ms\n",
      "Speed: 3.4ms preprocess, 34.7ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 35.4ms\n",
      "Speed: 4.6ms preprocess, 35.4ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 41.8ms\n",
      "Speed: 4.1ms preprocess, 41.8ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 33.6ms\n",
      "Speed: 10.8ms preprocess, 33.6ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 35.0ms\n",
      "Speed: 9.7ms preprocess, 35.0ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 35.0ms\n",
      "Speed: 3.5ms preprocess, 35.0ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 34.1ms\n",
      "Speed: 4.5ms preprocess, 34.1ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 35.7ms\n",
      "Speed: 3.9ms preprocess, 35.7ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 37.6ms\n",
      "Speed: 3.8ms preprocess, 37.6ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 35.4ms\n",
      "Speed: 5.4ms preprocess, 35.4ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 42.3ms\n",
      "Speed: 7.6ms preprocess, 42.3ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 39.0ms\n",
      "Speed: 4.1ms preprocess, 39.0ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 37.2ms\n",
      "Speed: 7.9ms preprocess, 37.2ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 41.3ms\n",
      "Speed: 3.5ms preprocess, 41.3ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 36.0ms\n",
      "Speed: 6.5ms preprocess, 36.0ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 34.7ms\n",
      "Speed: 4.2ms preprocess, 34.7ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 34.8ms\n",
      "Speed: 5.6ms preprocess, 34.8ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 33.9ms\n",
      "Speed: 4.0ms preprocess, 33.9ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 33.6ms\n",
      "Speed: 12.4ms preprocess, 33.6ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 33.5ms\n",
      "Speed: 9.4ms preprocess, 33.5ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 47.6ms\n",
      "Speed: 13.9ms preprocess, 47.6ms inference, 9.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 41.4ms\n",
      "Speed: 3.7ms preprocess, 41.4ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 35.0ms\n",
      "Speed: 3.4ms preprocess, 35.0ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 33.6ms\n",
      "Speed: 3.5ms preprocess, 33.6ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 33.6ms\n",
      "Speed: 4.7ms preprocess, 33.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 35.0ms\n",
      "Speed: 4.2ms preprocess, 35.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 33.0ms\n",
      "Speed: 3.4ms preprocess, 33.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 31.4ms\n",
      "Speed: 3.5ms preprocess, 31.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 31.8ms\n",
      "Speed: 4.9ms preprocess, 31.8ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 31.5ms\n",
      "Speed: 3.4ms preprocess, 31.5ms inference, 24.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 31.5ms\n",
      "Speed: 3.4ms preprocess, 31.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 31.4ms\n",
      "Speed: 3.7ms preprocess, 31.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 31.5ms\n",
      "Speed: 3.5ms preprocess, 31.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 31.4ms\n",
      "Speed: 3.5ms preprocess, 31.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 31.4ms\n",
      "Speed: 3.4ms preprocess, 31.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 31.4ms\n",
      "Speed: 3.9ms preprocess, 31.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 31.5ms\n",
      "Speed: 3.5ms preprocess, 31.5ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 31.4ms\n",
      "Speed: 3.5ms preprocess, 31.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 31.4ms\n",
      "Speed: 4.3ms preprocess, 31.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 31.3ms\n",
      "Speed: 3.4ms preprocess, 31.3ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 29.7ms\n",
      "Speed: 5.6ms preprocess, 29.7ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 3 spoileds, 31.0ms\n",
      "Speed: 3.3ms preprocess, 31.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 3 spoileds, 29.6ms\n",
      "Speed: 3.4ms preprocess, 29.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 2 spoileds, 30.2ms\n",
      "Speed: 3.5ms preprocess, 30.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 2 spoileds, 29.6ms\n",
      "Speed: 3.6ms preprocess, 29.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 29.6ms\n",
      "Speed: 3.5ms preprocess, 29.6ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 29.6ms\n",
      "Speed: 5.2ms preprocess, 29.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 29.6ms\n",
      "Speed: 3.3ms preprocess, 29.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 29.6ms\n",
      "Speed: 3.4ms preprocess, 29.6ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.5ms\n",
      "Speed: 5.8ms preprocess, 27.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.5ms\n",
      "Speed: 4.2ms preprocess, 27.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.9ms\n",
      "Speed: 3.3ms preprocess, 27.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 27.5ms\n",
      "Speed: 3.4ms preprocess, 27.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 27.6ms\n",
      "Speed: 3.5ms preprocess, 27.6ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 26.2ms\n",
      "Speed: 4.0ms preprocess, 26.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 26.1ms\n",
      "Speed: 3.6ms preprocess, 26.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 26.1ms\n",
      "Speed: 2.6ms preprocess, 26.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 26.2ms\n",
      "Speed: 8.3ms preprocess, 26.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 2 spoileds, 26.1ms\n",
      "Speed: 3.2ms preprocess, 26.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 1 spoiled, 26.1ms\n",
      "Speed: 3.5ms preprocess, 26.1ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 freshs, 2 spoileds, 26.5ms\n",
      "Speed: 4.8ms preprocess, 26.5ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fresh, 2 spoileds, 27.0ms\n",
      "Speed: 4.0ms preprocess, 27.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 26.1ms\n",
      "Speed: 3.5ms preprocess, 26.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 26.2ms\n",
      "Speed: 3.6ms preprocess, 26.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 26.1ms\n",
      "Speed: 4.4ms preprocess, 26.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 26.1ms\n",
      "Speed: 3.9ms preprocess, 26.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 26.1ms\n",
      "Speed: 4.4ms preprocess, 26.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 26.3ms\n",
      "Speed: 4.3ms preprocess, 26.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 26.1ms\n",
      "Speed: 5.4ms preprocess, 26.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 spoileds, 26.9ms\n",
      "Speed: 5.7ms preprocess, 26.9ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 26.1ms\n",
      "Speed: 3.9ms preprocess, 26.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 30.2ms\n",
      "Speed: 5.0ms preprocess, 30.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 29.6ms\n",
      "Speed: 4.0ms preprocess, 29.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 29.8ms\n",
      "Speed: 3.9ms preprocess, 29.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 30.2ms\n",
      "Speed: 3.5ms preprocess, 30.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 30.5ms\n",
      "Speed: 3.4ms preprocess, 30.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 30.8ms\n",
      "Speed: 3.5ms preprocess, 30.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 30.8ms\n",
      "Speed: 3.9ms preprocess, 30.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 30.8ms\n",
      "Speed: 4.5ms preprocess, 30.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 31.0ms\n",
      "Speed: 3.3ms preprocess, 31.0ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 31.4ms\n",
      "Speed: 4.1ms preprocess, 31.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 31.8ms\n",
      "Speed: 4.2ms preprocess, 31.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 32.1ms\n",
      "Speed: 3.1ms preprocess, 32.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 32.1ms\n",
      "Speed: 3.4ms preprocess, 32.1ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 32.1ms\n",
      "Speed: 3.3ms preprocess, 32.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 32.1ms\n",
      "Speed: 3.7ms preprocess, 32.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 32.1ms\n",
      "Speed: 3.5ms preprocess, 32.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 32.2ms\n",
      "Speed: 4.1ms preprocess, 32.2ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 32.8ms\n",
      "Speed: 4.2ms preprocess, 32.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.1ms\n",
      "Speed: 6.0ms preprocess, 33.1ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 6.3ms preprocess, 33.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.6ms preprocess, 33.6ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.7ms preprocess, 33.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 4.4ms preprocess, 33.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.9ms preprocess, 33.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 34.2ms\n",
      "Speed: 3.4ms preprocess, 34.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.6ms preprocess, 33.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.5ms\n",
      "Speed: 3.5ms preprocess, 33.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 33.6ms\n",
      "Speed: 3.8ms preprocess, 33.6ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.2ms preprocess, 33.6ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 4.5ms preprocess, 33.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.2ms preprocess, 33.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 4.2ms preprocess, 33.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 4.5ms preprocess, 33.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.7ms preprocess, 33.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.3ms preprocess, 33.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 3.3ms preprocess, 33.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.6ms\n",
      "Speed: 4.2ms preprocess, 33.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 33.0ms\n",
      "Speed: 3.4ms preprocess, 33.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 30.2ms\n",
      "Speed: 3.5ms preprocess, 30.2ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 spoiled, 30.2ms\n",
      "Speed: 5.0ms preprocess, 30.2ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 spoileds, 30.2ms\n",
      "Speed: 3.2ms preprocess, 30.2ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video processing complete. Output saved.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the video capture and the YOLO model\n",
    "video_path = \"/content/drive/My Drive/Colab Notebooks/small_spoiled_fruit_input_test_video.mp4\"\n",
    "video_path = \"/content/drive/My Drive/Colab Notebooks/spoiled_fruit_input_test_video.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Video writer to save output\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('/content/output_video_with_mask.mp4', fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "model = YOLO(\"/content/datasets/runs/segment/train/weights/best.pt\")  # Ensure the model path is correct\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Predict using the model\n",
    "    results = model.predict(source=frame, conf=0.25)  # Adjust confidence as needed\n",
    "\n",
    "    # Process each result\n",
    "    for result in results:\n",
    "        if hasattr(result, 'masks') and result.masks is not None:\n",
    "            for mask in result.masks.data:\n",
    "                mask = mask.cpu().numpy()\n",
    "                # Resize mask to match the frame dimensions\n",
    "                mask_resized = cv2.resize(mask, (frame_width, frame_height), interpolation=cv2.INTER_NEAREST)\n",
    "                # Create a color overlay only where the mask is positive\n",
    "                color_mask = np.zeros_like(frame)\n",
    "                color_mask[mask_resized > 0.5] = [0, 255, 0]  # Change [0, 255, 0] to any color you prefer\n",
    "\n",
    "                # Blend the color mask with the original frame\n",
    "                frame = cv2.addWeighted(frame, 1, color_mask, 0.4, 0)  # Adjust alpha to control transparency\n",
    "\n",
    "    # Write the processed frame to the output video\n",
    "    out.write(frame)\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "print(\"Video processing complete. Output saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vl1Ny6S0ekdc"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "BNo6-dCkc4FJ",
    "outputId": "97ee121e-ce81-4239-cc2e-4c2ce3a43c57"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_d2f3decd-62b5-4a74-abb4-d5e36de6da80\", \"output_video_with_mask.mp4\", 35210218)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "output_path='/content/output_video_with_mask.mp4'\n",
    "# Download the processed video file\n",
    "files.download(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y46MRylmk0z2"
   },
   "outputs": [],
   "source": [
    "!ls -ltr /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cur5uXxoVih5"
   },
   "outputs": [],
   "source": [
    "!apt-get install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lvGIfWJdtCi",
    "outputId": "00bed851-72a2-4957-a021-69dd0c4ea6dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'output_video_with_mask.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:00:12.35, start: 0.000000, bitrate: 22817 kb/s\n",
      "  Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], 22815 kb/s, 29 fps, 29 tbr, 14848 tbn, 29 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x59aa8cc8f580] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x59aa8cc8f580] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
      "\u001b[1;36m[libx264 @ 0x59aa8cc8f580] \u001b[0mprofile High, level 4.0, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x59aa8cc8f580] \u001b[0m264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'output_video_with_mask_conv.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 1920x1080 [SAR 1:1 DAR 16:9], q=2-31, 29 fps, 14848 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  358 fps=5.8 q=-1.0 Lsize=   12669kB time=00:00:12.24 bitrate=8478.3kbits/s speed=0.198x    \n",
      "video:12666kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.026723%\n",
      "\u001b[1;36m[libx264 @ 0x59aa8cc8f580] \u001b[0mframe I:2     Avg QP:22.48  size:242110\n",
      "\u001b[1;36m[libx264 @ 0x59aa8cc8f580] \u001b[0mframe P:293   Avg QP:24.29  size: 40559\n",
      "\u001b[1;36m[libx264 @ 0x59aa8cc8f580] \u001b[0mframe B:63    Avg QP:29.23  size:  9545\n",
      "\u001b[1;36m[libx264 @ 0x59aa8cc8f580] \u001b[0mconsecutive B-frames: 73.5%  7.8%  4.2% 14.5%\n",
      "\u001b[1;36m[libx264 @ 0x59aa8cc8f580] \u001b[0mmb I  I16..4:  4.1% 89.8%  6.1%\n",
      "\u001b[1;36m[libx264 @ 0x59aa8cc8f580] \u001b[0mmb P  I16..4:  3.1% 10.1%  0.5%  P16..4: 45.8% 13.7%  9.5%  0.0%  0.0%    skip:17.4%\n",
      "\u001b[1;36m[libx264 @ 0x59aa8cc8f580] \u001b[0mmb B  I16..4:  0.4%  1.6%  0.1%  B16..8: 39.7%  2.5%  0.8%  direct: 1.0%  skip:54.0%  L0:41.8% L1:47.4% BI:10.9%\n",
      "\u001b[1;36m[libx264 @ 0x59aa8cc8f580] \u001b[0m8x8 transform intra:74.2% inter:75.9%\n",
      "\u001b[1;36m[libx264 @ 0x59aa8cc8f580] \u001b[0mcoded y,uvDC,uvAC intra: 52.8% 66.7% 13.3% inter: 29.3% 24.6% 1.1%\n",
      "\u001b[1;36m[libx264 @ 0x59aa8cc8f580] \u001b[0mi16 v,h,dc,p: 35% 29% 17% 19%\n",
      "\u001b[1;36m[libx264 @ 0x59aa8cc8f580] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 25% 23% 30%  4%  4%  3%  4%  3%  5%\n",
      "\u001b[1;36m[libx264 @ 0x59aa8cc8f580] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 26% 20% 12%  7%  9%  7%  8%  5%  7%\n",
      "\u001b[1;36m[libx264 @ 0x59aa8cc8f580] \u001b[0mi8c dc,h,v,p: 45% 26% 24%  5%\n",
      "\u001b[1;36m[libx264 @ 0x59aa8cc8f580] \u001b[0mWeighted P-Frames: Y:5.8% UV:0.3%\n",
      "\u001b[1;36m[libx264 @ 0x59aa8cc8f580] \u001b[0mref P L0: 71.3% 23.5%  4.2%  1.0%  0.0%\n",
      "\u001b[1;36m[libx264 @ 0x59aa8cc8f580] \u001b[0mref B L0: 96.7%  2.8%  0.5%\n",
      "\u001b[1;36m[libx264 @ 0x59aa8cc8f580] \u001b[0mref B L1: 99.4%  0.6%\n",
      "\u001b[1;36m[libx264 @ 0x59aa8cc8f580] \u001b[0mkb/s:8404.64\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -i output_video_with_mask.mp4 -vcodec libx264 -y output_video_with_mask_conv.mp4\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "nDxk_nxRVmE8",
    "outputId": "1c4fedad-fd23-4aa6-8edd-016a67e23037"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "# Function to display the processed video\n",
    "def display_video(video_path):\n",
    "    mp4 = open(video_path,'rb').read()\n",
    "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "    return HTML(\"\"\"\n",
    "        <video width=700 controls>\n",
    "            <source src=\"%s\" type=\"video/mp4\">\n",
    "        </video>\n",
    "    \"\"\" % data_url)\n",
    "\n",
    "# Display the processed video\n",
    "display_video(\"output_video_with_mask_conv.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jfGG7h6PDxP"
   },
   "source": [
    "![Sample Output](spoil_video_out_3_mask.png)\n",
    "\n",
    "![Sample Output](spoil_video_out_4_mask.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0XHTD50PD-X"
   },
   "source": [
    "\n",
    "# You can watch the full video here\n",
    "\n",
    "\n",
    "https://github.com/AIBotTeachesAI/Segmentation_Spoiled_Fruit_YOLO/blob/main/README.md"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
